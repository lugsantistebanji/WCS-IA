{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454264a0-c172-4900-b4f8-2d9e22e50655",
   "metadata": {},
   "source": [
    "# __Download Datasets__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f3d46-0dd2-40ab-b6cd-ae55d112a72f",
   "metadata": {},
   "source": [
    "## IMDB Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf22171a-4f80-49db-9cff-778c56240d4f",
   "metadata": {},
   "source": [
    "[Imbd datastets](https://datasets.imdbws.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4736a21-76d0-4f05-9566-fe21381b6cd6",
   "metadata": {},
   "source": [
    "## TMDB Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d088ed-a46b-4a5b-a3d6-a6911b64ed2a",
   "metadata": {},
   "source": [
    "[Full TMDB Movies](https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a9921-00fd-4788-914c-7e9a2c03829c",
   "metadata": {},
   "source": [
    "[TMDB Dataset](https://drive.google.com/file/d/1VB5_gl1fnyBDzcIOXZ5vUSbCY68VZN1v/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff01687-a9c4-405d-b918-7d2a5daeaeea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# **TRANSFORMING DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6cec8-60e6-4baa-a781-299e18be7495",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **GENERAL FUNCTIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166f27d-94bb-4203-aad3-31d521f1a588",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da30d24c-55b0-4e4a-924f-c3c81aa731b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import StrEnum, unique, auto\n",
    "from IPython.display import clear_output\n",
    "from typing import List, Dict\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563561c6-e273-443a-918c-976faff9a510",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Clean Value function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b776fc-63f4-4c65-b4ec-cc9810f675f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_value(value, value_type=str):\n",
    "    \"\"\"Cleans the value according to the specified data type.\"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    value = str(value).replace(\"\\\\N\", \"\").strip('\"\\n\\t\\' ')\n",
    "    \n",
    "    if value_type == str:\n",
    "        if value == \"\":\n",
    "            value = None\n",
    "        else:\n",
    "            value = value.lower()\n",
    "    elif value_type == int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except:\n",
    "            value = None\n",
    "    elif value_type == bool:\n",
    "        try:\n",
    "            value = int(value)\n",
    "            value = value if value in [0,1] else None\n",
    "        except:\n",
    "            value_tmp = value.lower()\n",
    "            value = int(value_tmp == \"true\") if value_tmp in [\"false\", \"true\"] else None\n",
    "    elif value_type == float:\n",
    "        try:\n",
    "            value = float(value)\n",
    "        except:\n",
    "            value = None\n",
    "    elif value_type == list:\n",
    "        value = re.sub('[\\'\"\\\\[\\\\]]', \"\", value)\n",
    "        if isinstance(value, str) and value.count(\",\") > 0:\n",
    "            value = value.split(\",\")\n",
    "        elif isinstance(value, str) and len(value) > 0:\n",
    "            value = [value]\n",
    "        elif not isinstance(value, list):\n",
    "            value = []\n",
    "   \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03dec4-0456-4a1a-8e1d-ec096daaa342",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Extracting unique values function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23baab32-f6ed-45ca-8f65-6599631ea51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_column_values(file_path, delimiter, column_name_in_file, column_type=str, type_if_list=str, encoding='utf-8'):\n",
    "\n",
    "        unique_values = set()\n",
    "\n",
    "        try:\n",
    "            with open(file_path, newline='', encoding=encoding) as file:\n",
    "                reader = csv.DictReader(file, delimiter=delimiter)\n",
    "\n",
    "                for row in reader:\n",
    "                    value = row[column_name_in_file]\n",
    "                    cleaned_value = clean_value(value, value_type=column_type)\n",
    "                    if isinstance(cleaned_value, list):\n",
    "                        for item in cleaned_value:\n",
    "                            cleaned_item = clean_value(item, value_type=type_if_list)\n",
    "                            if cleaned_item is not None:\n",
    "                                unique_values.add(cleaned_item)\n",
    "                    elif cleaned_value is not None:\n",
    "                        unique_values.add(cleaned_value)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: File not found: {e}\")\n",
    "            raise\n",
    "        except csv.Error as e:\n",
    "            print(f\"Error reading the file: {e}\")\n",
    "            raise\n",
    "\n",
    "        return unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723fe48c-3277-47ea-a381-44b2e7e44851",
   "metadata": {},
   "source": [
    "#### **Extracting uniques tuples values function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dacd9b82-3989-49b2-a9c7-7812725a8ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_tuples_values(file_path, delimiter, columns: Dict, encoding='utf-8'):\n",
    "\n",
    "        unique_values = set()\n",
    "\n",
    "        try:\n",
    "            with open(file_path, newline='', encoding=encoding) as file:\n",
    "                reader = csv.DictReader(file, delimiter=delimiter)\n",
    "\n",
    "                for row in reader:\n",
    "                    tuple_value = tuple([clean_value(row[column],type_value) for column, type_value in columns.items()])\n",
    "                    unique_values.add(tuple_value)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: File not found: {e}\")\n",
    "            raise\n",
    "        except csv.Error as e:\n",
    "            print(f\"Error reading the file: {e}\")\n",
    "            raise\n",
    "\n",
    "        return [{key:value for key, value in zip(columns.keys(),tuple_n)} for tuple_n in unique_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7005c-5302-4e48-b5fc-261a01f22f89",
   "metadata": {},
   "source": [
    "#### **Printing unique values function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab400562-06a0-41f9-9026-2d831559c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_values(unique_values, name, columns=3):\n",
    "    print(f\"TOTAL : {len(unique_values)}\")\n",
    "    print(f\"{name.upper()} :\")\n",
    "    max_length = max(len(value) for value in unique_values) + 4\n",
    "    \n",
    "    for index, value in enumerate(unique_values, start=1):\n",
    "        if index % columns == 1 and columns > 1:\n",
    "            print(f\"\\t{value.ljust(max_length)}\", end=\"\")\n",
    "        elif columns == 1 or (index % columns) == 0:\n",
    "            print(f\"{value}\")\n",
    "        else:\n",
    "            print(f\"{value.ljust(max_length)}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7ca24-d7d9-48b6-a13b-f6e01a9a5c22",
   "metadata": {},
   "source": [
    "#### **Cartesien product of dictionnaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf95f35-ef78-4f34-906d-573347730fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cartesian_product(pools:List[List[Dict]]):\n",
    "    result = [{}]\n",
    "    for pool in pools:\n",
    "        result = [{**x, **y} for x in result for y in pool]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aac264-9a0f-4eb0-a377-5f9511140f07",
   "metadata": {},
   "source": [
    "#### **Cartesien product of two listes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e2ae32-ad75-48a9-88af-8abd1c461023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cartesian_product_simple(list_1: List, list_2: List):\n",
    "    result = [(x, y) for x in list_1 for y in list_2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46a74d-bffc-4479-84e2-1d330ff63b9f",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## **INITIAL ANALYSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ddd639-8a73-47c6-92c3-448e205fd196",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **IMDB FILE: `title.basics.tsv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e67a2da5-858b-43b6-9c65-168a5c182686",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"../Data_Files/data/title.basics.tsv\"\n",
    "delimiter = \"\\t\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd4e7d-a9c0-4257-87cc-b0b907c5b625",
   "metadata": {},
   "source": [
    "#### **Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6c2f3581-2c0d-445e-98ed-59e30dbd8014",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 28\n",
      "GENRES :\n",
      "\tAction         Adult          Adventure      Animation\n",
      "\tBiography      Comedy         Crime          Documentary\n",
      "\tDrama          Ews            Family         Fantasy\n",
      "\tFilm-noir      Game-show      History        Horror\n",
      "\tMusic          Musical        Mystery        Reality-tv\n",
      "\tRomance        Sci-fi         Short          Sport\n",
      "\tTalk-show      Thriller       War            Western\n"
     ]
    }
   ],
   "source": [
    "unique_genres = sorted(extract_unique_column_values(file_path, delimiter, \"genres\", column_type=list))\n",
    "print_unique_values(unique_genres, \"genres\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99113fe8-6436-4456-9ef3-4c788c12a2cb",
   "metadata": {},
   "source": [
    "#### **Formats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d4e8d89c-3034-4fae-ac2a-d42995eb3639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 11\n",
      "FORMAT :\n",
      "\tMovie           Short           Tvepisode       Tvminiseries\n",
      "\tTvmovie         Tvpilot         Tvseries        Tvshort\n",
      "\tTvspecial       Video           Videogame       "
     ]
    }
   ],
   "source": [
    "unique_formats = sorted(extract_unique_column_values(file_path, delimiter, \"titleType\", column_type=str))\n",
    "print_unique_values(unique_formats, \"Format\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef6630-703b-4c79-9d48-4b9a6a8ee11b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **IMDB FILE: `title.akas.tsv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7b026d0a-af80-4722-9118-d5c369145d1f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"../Data_Files/data/title.akas.tsv\"\n",
    "delimiter = \"\\t\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547816e5-a074-4fdd-9d61-c83eecabad9f",
   "metadata": {},
   "source": [
    "#### **Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "7f6c4241-c876-4a43-9ec0-8a5fd2e8fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 23\n",
      "TYPES :\n",
      "\tAlternative             Alternative\u0002festival    Alternative\u0002tv          Alternative\u0002video\n",
      "\tDvd                     Dvd\u0002alternative         Dvd\u0002video               Festival\n",
      "\tImdbdisplay             Imdbdisplay\u0002dvd         Imdbdisplay\u0002festival    Imdbdisplay\u0002tv\n",
      "\tImdbdisplay\u0002video       Imdbdisplay\u0002working     Original                Tv\n",
      "\tTv\u0002video                Video                   Working                 Working\u0002alternative\n",
      "\tWorking\u0002festival        Working\u0002tv              Working\u0002video           "
     ]
    }
   ],
   "source": [
    "unique_types = sorted(extract_unique_column_values(file_path, delimiter, \"types\", column_type=list))\n",
    "print_unique_values(unique_types, \"Types\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cc831e6d-65a0-4a99-8a87-37888eb10912",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_imdb = [\"alternative\", \"dvd\", \"festival\", \"tv\", \"video\", \"working\", \"original\", \"imdbDisplay\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182267f8-7139-405b-95a3-151bc38da4e9",
   "metadata": {},
   "source": [
    "#### **Languages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "73ab7fb3-2ad1-4eb9-8fe5-299a7d80fdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 108\n",
      "LANGUAGES :\n",
      "\tAf     Am     Ar     Az     Be     Bg     Bn     Br     Bs     Ca     Cmn    Cr\n",
      "\tCs     Cy     Da     De     Eka    El     En     Es     Et     Eu     Fa     Fi\n",
      "\tFr     Fro    Ga     Gd     Gl     Gsw    Gu     Haw    He     Hi     Hil    Hr\n",
      "\tHu     Hy     Id     Is     It     Iu     Ja     Jsl    Jv     Ka     Kk     Kn\n",
      "\tKo     Ku     Ky     La     Lb     Lo     Lt     Lv     Mi     Mk     Ml     Mn\n",
      "\tMr     Ms     My     Myv    Ne     Nl     No     Pa     Pl     Prs    Ps     Pt\n",
      "\tQac    Qal    Qbn    Qbo    Qbp    Rm     Rn     Ro     Roa    Ru     Sd     Sk\n",
      "\tSl     Sq     Sr     St     Su     Sv     Ta     Te     Tg     Th     Tk     Tl\n",
      "\tTn     Tr     Uk     Ur     Uz     Vi     Wo     Xh     Yi     Yue    Zh     Zu\n"
     ]
    }
   ],
   "source": [
    "unique_languages = sorted(extract_unique_column_values(file_path, delimiter, \"language\", column_type=str))\n",
    "print_unique_values(unique_languages, \"Languages\", 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6122de9-5a6e-49a2-bbb9-407de5079adb",
   "metadata": {},
   "source": [
    "#### **Regions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "82c7ac90-feca-48c7-9abc-1bbac05b8615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 244\n",
      "REGIONS :\n",
      "\tA       Ad      Ae      Af      Ag      Ai      Al      Am      Ao      Aq      Ar      As\n",
      "\tAt      Au      Aw      Az      B       Ba      Bb      Bd      Be      Bf      Bg      Bh\n",
      "\tBi      Bj      Bm      Bo      Br      Bs      Bt      Bumm    Bw      By      Bz      C\n",
      "\tCa      Cc      Cd      Cf      Cg      Ch      Ci      Ck      Cl      Cm      Co      Cr\n",
      "\tCshh    Csxx    Cu      Cv      Cw      Cy      Cz      Ddde    De      Dj      Dk      Dm\n",
      "\tDo      Dz      E       Ec      Ee      Eg      Eh      Er      Es      Et      Fi      Fj\n",
      "\tFm      Fo      Fr      G       Ga      Gb      Gd      Ge      Gf      Gh      Gi      Gl\n",
      "\tGm      Gp      Gq      Gr      Gt      Gu      Gw      Gy      H       Hk      Hr      Ht\n",
      "\tHu      I       Id      Ie      Il      Im      Iq      Ir      Is      It      Je      Jm\n",
      "\tJo      Jp      K       Ke      Kg      Kh      Ki      Km      Kp      Kr      Kw      Ky\n",
      "\tKz      L       La      Lb      Lc      Li      Lk      Lr      Ls      Lt      Lu      Lv\n",
      "\tLy      M       Ma      Mc      Md      Me      Mg      Mh      Mk      Ml      Mm      Mo\n",
      "\tMp      Mq      Mr      Ms      Mt      Mu      Mv      Mw      Mx      My      Mz      O\n",
      "\tOm      P       Pa      Pe      Pf      Pg      Ph      Pk      Pl      Pr      Ps      Pt\n",
      "\tPw      Py      Qa      R       Re      Ro      Rs      Ru      Rw      S       Sa      Sb\n",
      "\tSc      Sd      Se      Sg      Sh      Si      Sk      Sl      Sm      So      Sr      St\n",
      "\tSuhh    Sv      Sy      Sz      T       Tc      Td      Tg      Th      Tj      Tl      Tm\n",
      "\tTo      Tr      Tt      Tv      Tw      Tz      U       Ua      Ug      Us      Uy      Uz\n",
      "\tV       Va      Vc      Vdv     Ve      Vg      Vi      Vu      Ws      Xas     Xau     Xeu\n",
      "\tXko     Xkv     Xna     Xpi     Xsa     Xsi     Xwg     Xww     Xyu     Ye      Yucs    Z\n",
      "\tZa      Zm      Zrcd    Zw      "
     ]
    }
   ],
   "source": [
    "unique_regions = sorted(extract_unique_column_values(file_path, delimiter, \"region\", column_type=str))\n",
    "print_unique_values(unique_regions, \"Regions\", 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f5c0c-450d-4f56-bbe2-0565773dab3e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **IMDB FILE: `title.principal.tsv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a33334-d55e-4e5a-84f3-2f3ca14a8b36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"../Data_Files/data/title.principals.tsv\"\n",
    "delimiter = \"\\t\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92181f4-361c-4ed1-9d15-7f6a34ea6c17",
   "metadata": {},
   "source": [
    "#### **Job Titles**\n",
    "\n",
    "It's not a interesting field because there are 42663 jobs, so, there are not generate a relation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e26f7-0d17-4e28-9553-6c3f41c9d89a",
   "metadata": {},
   "source": [
    "#### **Job Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "76b15424-eef5-4466-9ee9-0d1cd9fc435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 13\n",
      "JOBS CATEGORIES :\n",
      "\tActor                  Actress                Archive_footage        Archive_sound\n",
      "\tCasting_director       Cinematographer        Composer               Director\n",
      "\tEditor                 Producer               Production_designer    Self\n",
      "\tWriter                 "
     ]
    }
   ],
   "source": [
    "unique_jobs_categories = sorted(extract_unique_column_values(file_path, delimiter, \"category\", column_type=str))\n",
    "print_unique_values(unique_jobs_categories, \"Jobs Categories\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9272812-2492-42cb-9e0b-9b6c9dc2e412",
   "metadata": {},
   "source": [
    "#### **Creating new file with only tuples (tconst, nconst, category)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d987c4cf-41bb-4f69-a9df-9a6510a7ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data_Files/data/title.principals.filtered.tsv\", \"w\", newline=\"\", encoding=\"utf-8\") as new_file:\n",
    "    columns = {'tconst': str, \"nconst\": str, \"category\": str}\n",
    "    writer = csv.DictWriter(new_file,fieldnames=columns.keys(), delimiter=delimiter)\n",
    "    writer.writeheader()\n",
    "    uniques = extract_unique_tuples_values(file_path=file_path, delimiter=delimiter, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ce330-2604-4c87-8bb7-fe19a87f00c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **IMDB FILE: `name.basics.tsv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2a63293f-2e0d-4482-af55-8f776ea0c24f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"../Data_Files/data/name.basics.tsv\"\n",
    "delimiter = \"\\t\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3fce3-1ae0-4bc3-a5e0-893bb7622a03",
   "metadata": {},
   "source": [
    "#### **Professions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "02d85e6c-92fc-4334-9537-54d282fc60b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 46\n",
      "PROFESSIONS :\n",
      "\tAccountant                   Actor                        Actress                      Animation_department\n",
      "\tArchive_footage              Archive_sound                Art_department               Art_director\n",
      "\tAssistant                    Assistant_director           Camera_department            Casting_department\n",
      "\tCasting_director             Choreographer                Cinematographer              Composer\n",
      "\tCostume_department           Costume_designer             Director                     Editor\n",
      "\tEditorial_department         Electrical_department        Executive                    Legal\n",
      "\tLocation_management          Make_up_department           Manager                      Miscellaneous\n",
      "\tMusic_artist                 Music_department             Podcaster                    Producer\n",
      "\tProduction_department        Production_designer          Production_manager           Publicist\n",
      "\tScript_department            Set_decorator                Sound_department             Soundtrack\n",
      "\tSpecial_effects              Stunts                       Talent_agent                 Transportation_department\n",
      "\tVisual_effects               Writer                       "
     ]
    }
   ],
   "source": [
    "unique_professions = sorted(extract_unique_column_values(file_path, delimiter, \"primaryProfession\", column_type=list))\n",
    "print_unique_values(unique_professions, \"Professions\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "a3637a7c-c21e-45cc-a57e-b8c6aba905ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for job in unique_jobs_categories:\n",
    "    if job not in unique_professions:\n",
    "        print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec59638-d835-4b6b-a551-e14e84d6db25",
   "metadata": {},
   "source": [
    "### **TMDB FILE : `tmdb_full_separator.csv`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41c228cb-6512-47b1-8384-31970f200fd6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"../Data_Files/data/TMDB_movie_dataset_v11_separator.csv\"\n",
    "delimiter = \"|\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7e241-96d2-4885-b767-4a2c8374390f",
   "metadata": {},
   "source": [
    "#### **Production Countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e99b5a44-3645-4aba-8576-15cae0dbfa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 228\n",
      "PRODUCTION COUNTRIES :\n",
      "\tA     Ad    Ae    Af    Ag    Ai    Al    Am    Ao    Aq    Ar    At\n",
      "\tAu    Aw    Az    B     Ba    Bb    Bd    Be    Bf    Bg    Bh    Bi\n",
      "\tBj    Bm    Bo    Br    Bs    Bt    Bw    By    Bz    C     Ca    Cd\n",
      "\tCf    Cg    Ch    Ci    Ck    Cl    Cm    Co    Cr    Cs    Cu    Cv\n",
      "\tCx    Cy    Cz    De    Dj    Dk    Dm    Do    Dz    E     Ec    Ee\n",
      "\tEg    Eh    Er    Es    Et    F     Fi    Fj    Fk    Fm    Fo    Fr\n",
      "\tG     Ga    Gb    Gd    Ge    Gf    Gh    Gi    Gl    Gm    Gp    Gq\n",
      "\tGr    Gt    Gu    Gw    Gy    H     Hk    Hr    Ht    Hu    I     Id\n",
      "\tIe    Il    Io    Iq    Ir    Is    It    Jm    Jo    Jp    K     Ke\n",
      "\tKg    Kh    Ki    Km    Kp    Kr    Kw    Ky    Kz    L     La    Lb\n",
      "\tLc    Li    Lk    Lr    Ls    Lt    Lu    Lv    Ly    M     Ma    Mc\n",
      "\tMd    Me    Mg    Mh    Mk    Ml    Mm    Mo    Mq    Mr    Ms    Mt\n",
      "\tMu    Mv    Mw    Mx    My    Mz    O     Om    P     Pa    Pe    Pf\n",
      "\tPg    Ph    Pk    Pl    Pm    Pr    Ps    Pt    Pw    Py    Qa    Re\n",
      "\tRo    Rs    Ru    Rw    S     Sa    Sb    Sd    Se    Sg    Sh    Si\n",
      "\tSj    Sk    Sl    Sm    So    Sr    Ss    Su    Sv    Sy    Sz    T\n",
      "\tTc    Td    Tg    Th    Tj    Tl    Tm    To    Tr    Tt    Tw    Tz\n",
      "\tUa    Ug    Um    Us    Uy    Uz    V     Va    Vc    Ve    Vg    Vi\n",
      "\tVu    Ws    Xc    Xg    Xi    Xk    Ye    Yu    Z     Za    Zm    Zw\n"
     ]
    }
   ],
   "source": [
    "unique_production_countries = sorted(extract_unique_column_values(file_path, delimiter, \"production_countries\", column_type=list))\n",
    "print_unique_values(unique_production_countries, \"Production Countries\", 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "813cc792-a439-4307-9fb2-a8a5c2481d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606752\n"
     ]
    }
   ],
   "source": [
    "unique_imdb_ids = sorted(extract_unique_column_values(file_path, delimiter, \"imdb_id\", column_type=str))\n",
    "print(len(unique_imdb_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9dc446d-404e-4db8-8264-9adc7247095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158058\n"
     ]
    }
   ],
   "source": [
    "unique_tmdb_ids = sorted(extract_unique_column_values(file_path, delimiter, \"id\", column_type=str))\n",
    "print(len(unique_tmdb_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672dcc23-2143-4203-8dd2-9bf2bebb1000",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Original languages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0dd1a364-6350-4cf1-b69a-445abe7ba0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 152\n",
      "ORIGINAL LANGUAGES :\n",
      "\tAb    Af    Ak    Am    Ar    As    Ay    Az    Ba    Be    Bg    Bm\n",
      "\tBn    Bo    Bs    Ca    Ce    Cn    Co    Cr    Cs    Cv    Cy    Da\n",
      "\tDe    Dv    Dz    El    En    Eo    Es    Et    Eu    Fa    Ff    Fi\n",
      "\tFo    Fr    Fy    Ga    Gd    Gl    Gn    Gu    Ha    He    Hi    Hr\n",
      "\tHt    Hu    Hy    Ia    Id    Ie    Ig    Ik    Is    It    Iu    Ja\n",
      "\tJv    Ka    Kg    Kk    Kl    Km    Kn    Ko    Ks    Ku    Kw    Ky\n",
      "\tLa    Lb    Lg    Li    Ln    Lo    Lt    Lv    Mg    Mh    Mi    Mk\n",
      "\tMl    Mn    Mo    Mr    Ms    Mt    My    Nb    Ne    Nl    Nn    No\n",
      "\tNv    Ny    Oc    Om    Or    Os    Pa    Pl    Ps    Pt    Qu    Rm\n",
      "\tRo    Ru    Rw    Sa    Sc    Sd    Se    Sg    Sh    Si    Sk    Sl\n",
      "\tSm    So    Sq    Sr    Ss    St    Su    Sv    Sw    Ta    Te    Tg\n",
      "\tTh    Tk    Tl    Tn    To    Tr    Tt    Tw    Ug    Uk    Ur    Uz\n",
      "\tVi    Wo    Xh    Xx    Yi    Yo    Zh    Zu    "
     ]
    }
   ],
   "source": [
    "unique_original_languages = sorted(extract_unique_column_values(file_path, delimiter, \"original_language\", column_type=str))\n",
    "print_unique_values(unique_original_languages, \"Original Languages\", 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd5ecce-f96f-42bd-971b-5b5c8034bb24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Spoken languages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5537c867-ff50-4411-815d-5fc87ab53615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 177\n",
      "SPOKEN LANGUAGES :\n",
      "\tAa    Ab    Af    Ak    Am    An    Ar    As    Av    Ay    Az    Ba\n",
      "\tBe    Bg    Bi    Bm    Bn    Bo    Br    Bs    Ca    Ce    Ch    Cn\n",
      "\tCo    Cr    Cs    Cu    Cv    Cy    Da    De    Dv    Dz    Ee    El\n",
      "\tEn    Eo    Es    Et    Eu    Fa    Ff    Fi    Fj    Fo    Fr    Fy\n",
      "\tGa    Gd    Gl    Gn    Gu    Ha    He    Hi    Ho    Hr    Ht    Hu\n",
      "\tHy    Hz    Ia    Id    Ie    Ig    Ii    Ik    Io    Is    It    Iu\n",
      "\tJa    Jv    Ka    Kg    Ki    Kk    Kl    Km    Kn    Ko    Ks    Ku\n",
      "\tKw    Ky    La    Lb    Lg    Li    Ln    Lo    Lt    Lv    Mg    Mh\n",
      "\tMi    Mk    Ml    Mn    Mo    Mr    Ms    Mt    My    Na    Nb    Ne\n",
      "\tNg    Nl    Nn    No    Nr    Nv    Ny    Oc    Oj    Om    Or    Os\n",
      "\tPa    Pi    Pl    Ps    Pt    Qu    Rm    Rn    Ro    Ru    Rw    Sa\n",
      "\tSc    Sd    Se    Sg    Sh    Si    Sk    Sl    Sm    Sn    So    Sq\n",
      "\tSr    Ss    St    Su    Sv    Sw    Ta    Te    Tg    Th    Ti    Tk\n",
      "\tTl    Tn    To    Tr    Tt    Tw    Ty    Ug    Uk    Ur    Uz    Ve\n",
      "\tVi    Wa    Wo    Xh    Xx    Yi    Yo    Zh    Zu    "
     ]
    }
   ],
   "source": [
    "unique_spoken_languages = sorted(extract_unique_column_values(file_path, delimiter, \"spoken_languages\", column_type=list))\n",
    "print_unique_values(unique_spoken_languages, \"Spoken Languages\", 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b178c4-9c30-47ad-a778-2d70e2726ffc",
   "metadata": {},
   "source": [
    "#### **Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b057b154-9ec6-4b88-8786-2b51c8ab3db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 6\n",
      "STATUS :\n",
      "\tCanceled           In production      Planned            Post production    Released           Rumored            "
     ]
    }
   ],
   "source": [
    "unique_status = sorted(extract_unique_column_values(file_path, delimiter, \"status\", column_type=list))\n",
    "print_unique_values(unique_status, \"Status\", 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c84e77-2e53-4ef0-9c3e-7b9f070c8f66",
   "metadata": {},
   "source": [
    "#### **Production Companies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fe1e274e-2b99-4208-86ab-9892d8fb6c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 100\n",
      "PRODUCTION COMPANIES :\n",
      "\t20th century fox                            20th century fox animation\n",
      "\ta band apart                                albert s. ruddy productions\n",
      "\taltavista films                             amblin entertainment\n",
      "\tamercent films                              american entertainment partners l.p.\n",
      "\tamerican zoetrope                           angel films\n",
      "\tanonymous content                           ard\n",
      "\tarte                                        arte france cinéma\n",
      "\tarts council of england                     atlas entertainment\n",
      "\tatresmedia                                  augustus film\n",
      "\tbakshi productions                          bbc film\n",
      "\tbeijing new picture film co. ltd.           benderspink\n",
      "\tbeta film                                   bill/phillips\n",
      "\tblind spot pictures                         bruce brown films\n",
      "\tbuena vista international                   c & l\n",
      "\tcanal+                                      castle rock entertainment\n",
      "\tcatfish productions                         ced productions\n",
      "\tchina film co-production corporation        cineclick asia\n",
      "\tcinematograph a/s                           cinesecolo\n",
      "\tcinesoul                                    classico\n",
      "\tcolumbia pictures                           constantin film\n",
      "\tcruise/wagner productions                   davis entertainment\n",
      "\tdawliz                                      dentsu\n",
      "\tdentsu music and entertainment              det danske filminstitut\n",
      "\tdetour filmproduction                       don simpson/jerry bruckheimer films\n",
      "\tdr                                          dreamworks pictures\n",
      "\tdrew associates                             eal street productions\n",
      "\teddie murphy productions                    ederlands fonds voor de film\n",
      "\tel deseo                                    embassy international pictures\n",
      "\tepsilon motion pictures                     estudios churubusco azteca s.a.\n",
      "\teurimages                                   ew line cinema\n",
      "\tewmarket capital group                      fama film ag\n",
      "\tfantasy films                               film i väst\n",
      "\tfilm polski                                 film roman\n",
      "\tfilm4 productions                           filmek a/s\n",
      "\tfilmhaus films                              filmstiftung nordrhein-westfalen\n",
      "\tfine line features                          focus features\n",
      "\tfoqus arte digital                          forward pass\n",
      "\tfox 2000 pictures                           france 2 cinéma\n",
      "\tfrance 3 cinéma                             gaumont\n",
      "\tgood machine                                gracie films\n",
      "\tgramercy pictures                           great american films limited partnership\n",
      "\thamburger filmschule                        handmade films\n",
      "\thazazah pictures                            i remember productions\n",
      "\tibariki                                     imagine entertainment\n",
      "\timpact pictures                             inloops\n",
      "\tippon television network corporation        isle of man film\n",
      "\titalo/judeo productions                     jerry bruckheimer films\n",
      "\tjinks/cohen company                         jvc\n",
      "\tkonrad pictures                             korea pictures\n",
      "\tlakeshore entertainment                     lama films\n"
     ]
    }
   ],
   "source": [
    "unique_production_companies = sorted(extract_unique_column_values(file_path, delimiter, \"production_companies_name\", column_type=list))\n",
    "print_unique_values(unique_production_companies[:100], \"Production Companies\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f066d8e0-6fc2-48d7-874a-4c92abba1038",
   "metadata": {},
   "source": [
    "#### **Production Companies Countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "7ed0d291-13be-490c-9b6c-a90f719acea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 25\n",
      "PRODUCTION COMPANIES COUNTRIES :\n",
      "\tat    ch    de    dk    es    fi    fr    gb    hk    il\n",
      "\tis    it    jp    kr    l     ma    mt    mx    pl    ps\n",
      "\tpy    se    us    uy    z     "
     ]
    }
   ],
   "source": [
    "unique_production_companies_countries = sorted(extract_unique_column_values(file_path, delimiter, \"production_companies_country\", column_type=list))\n",
    "print_unique_values(unique_production_companies_countries, \"Production Companies Countries\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4abda-d589-49a8-85bc-5ef7420e7b5a",
   "metadata": {},
   "source": [
    "### **Languages and regions/countries verifications** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1601ea-e391-4eed-8e68-b74b796faf74",
   "metadata": {},
   "source": [
    "#### **Languages codes to use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "0920e88d-20c4-44ed-bf0a-fd004c8f0d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGUAGES NOT FOUND :\n",
      "set()\n",
      "set()\n",
      "{'qac'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"../Data_Files/data/language-codes.csv\") as file:\n",
    "    reader = csv.DictReader(file, delimiter=\",\")\n",
    "    languages_in_file = set()\n",
    "    for row in reader:\n",
    "        languages_in_file.add(row['code'].lower())\n",
    "    spoken_languages = set([language.lower() for language in unique_spoken_languages])\n",
    "    original_languages = set([language.lower() for language in unique_original_languages])\n",
    "    imdb_languages = set([language.lower() for language in unique_languages])\n",
    "    \n",
    "    spoken_languages_not_in_file = spoken_languages.difference(languages_in_file)\n",
    "    original_languages_not_in_file = original_languages.difference(languages_in_file)\n",
    "    imdb_languages_not_in_file = imdb_languages.difference(languages_in_file)\n",
    "\n",
    "    print(\"LANGUAGES NOT FOUND :\")\n",
    "    print(spoken_languages_not_in_file)\n",
    "    print(original_languages_not_in_file)\n",
    "    print(imdb_languages_not_in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db40f1f5-910b-483e-ba66-601e896997df",
   "metadata": {},
   "source": [
    "#### **Regions codes to use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "4254dd9a-5c91-4799-b15a-133fcf5ec09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGIONS NOT FOUND :\n",
      "{'z', 'h', 'xg', 'm', 't', 's', 'g', 'p', 'i', 'e', 'o', 'a', 'c', 'b', 'f', 'v', 'k', 'l', 'xi', 'xc'}\n",
      "{'z', 'l'}\n",
      "{'z', 's', 'c', 'h', 'e', 'b', 'g', 'v', 'k', 'p', 'l', 'i', 'u', 'o', 'r', 'm', 't', 'a'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"../Data_Files/data/regions-codes.csv\") as file:\n",
    "    reader = csv.DictReader(file, delimiter=\",\")\n",
    "    regions_in_file = set()\n",
    "    for row in reader:\n",
    "        regions_in_file.add(row['code'].lower())\n",
    "    production_countries = set([region.lower() for region in unique_production_countries])\n",
    "    production_companies_countries = set([region.lower() for region in unique_production_companies_countries])\n",
    "    imdb_regions = set([region.lower() for region in unique_regions])\n",
    "    \n",
    "    production_countries_not_in_file = production_countries.difference(regions_in_file)\n",
    "    production_companies_countries_not_in_file = production_companies_countries.difference(regions_in_file)\n",
    "    imdb_regions_not_in_file = imdb_regions.difference(regions_in_file)\n",
    "\n",
    "    print(\"REGIONS NOT FOUND :\")\n",
    "    print(production_countries_not_in_file)\n",
    "    print(production_companies_countries_not_in_file)\n",
    "    print(imdb_regions_not_in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7654c-59fe-4884-a4b1-c8a51928595b",
   "metadata": {},
   "source": [
    "### **Creation of file `productions_companies.csv` from `tmdb_full_separator.csv` file** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "908359b0-8263-4728-8ba4-331d340e0c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_companies_file = \"../Data_Files/data/production_companies.csv\"\n",
    "delimiter_production_companies_file = \"|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "59da21d7-3ae5-42a7-840d-ab1b0521ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_str_like_lists(text1, text2):\n",
    "    list_1 = clean_value(text1, list)\n",
    "    list_2 = clean_value(text2, list)\n",
    "    result_list = []\n",
    "    \n",
    "    list_1_clean = [clean_value(value, str) for value in list_1]\n",
    "    list_2_clean = [clean_value(value, str) for value in list_2]\n",
    "\n",
    "    size_list_1 = len(list_1_clean)\n",
    "    size_list_2 = len(list_2_clean)\n",
    "    \n",
    "    \n",
    "    if size_list_1 > 0:\n",
    "        for val in reversed(list_2_clean):\n",
    "            if val == None : list_2_clean.pop()\n",
    "            else : break\n",
    "        size_list_2 = len(list_2_clean)\n",
    "                    \n",
    "        if size_list_2 >= size_list_1:\n",
    "            result_list = [(val_1, val_2) for val_1, val_2 in zip(list_1_clean, list_2_clean)] \n",
    "        elif size_list_2 > 0:\n",
    "            result_list = [(val_1, val_2) for val_1, val_2 in zip(list_1_clean[:size_list_2], list_2_clean)]\n",
    "            result_list += get_cartesian_product_simple(list_1_clean[size_list_2:],[list_2_clean[-1]])                \n",
    "        else:\n",
    "            result_list = [(val_1, None) for val_1 in list_1_clean]\n",
    "        \n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "64ed9933-78a6-4d45-ac0c-6315d51e6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_tuples_to_dict_key_set(list_of_tuples: List) -> Dict:\n",
    "    result_dict = {}\n",
    "    for val1, val2 in list_of_tuples:\n",
    "        if val1 not in result_dict.keys():\n",
    "            result_dict[val1] = None\n",
    "        if val2 != None: result_dict[val1] = val2\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8abb82bd-ad59-4a6f-9019-225ffd2d91fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...\n",
      "Writing file...\n",
      "File writed with success...\n"
     ]
    }
   ],
   "source": [
    "companies_in_file = set()\n",
    "\n",
    "with open(\"../Data_Files/data/tmdb_full_separator.csv\", \"r\", newline='', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file, delimiter=\"|\")\n",
    "    print(\"Reading file...\")\n",
    "    for row in reader:\n",
    "        production_companies_name = row['production_companies_name']\n",
    "        production_companies_country = row['production_companies_country']\n",
    "        \n",
    "        companies_in_file.update(process_str_like_lists(\n",
    "            production_companies_name, \n",
    "            production_companies_country\n",
    "        ))\n",
    "companies_region_dict = list_of_tuples_to_dict_key_set(companies_in_file)           \n",
    "companies_in_file_dict = [{\"company_name\": company, \"region_code\": region} for company, region in companies_region_dict.items() if company is not None]\n",
    "companies_in_file_dict = sorted(companies_in_file_dict, key=lambda x: x[\"company_name\"])\n",
    "with open(production_companies_file, \"w\", newline='', encoding='utf-8') as file:\n",
    "    print(\"Writing file...\")\n",
    "    fieldnames = [\"company_name\", \"region_code\"]\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames, delimiter=delimiter_production_companies_file)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(companies_in_file_dict)\n",
    "    print(\"File writed with success...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f007395c-f348-4343-a3df-bd08940be9c0",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5adff-9ff4-4f3f-81fd-b0750c78ecfe",
   "metadata": {},
   "source": [
    "## **FILES INFORMATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43880d-5539-401a-9ecb-65ae560b586b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __Script `info_file.sh`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a7dce-168a-46a2-990b-c10692b02d45",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "\n",
    "separator=\"\\\\t\"\n",
    "\n",
    "while getopts 's:f:' OPTION; do \n",
    "  case \"$OPTION\" in \n",
    "    s)\n",
    "      separator=\"$OPTARG\"\n",
    "      ;;\n",
    "    f)\n",
    "      archivo=\"$OPTARG\"\n",
    "      ;;\n",
    "  esac\n",
    "done\n",
    "\n",
    "\n",
    "if [ -z \"$archivo\" ]; then\n",
    "  echo \"Uso: $0 -f <file>\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "\n",
    "filename=$(basename -- \"$archivo\")\n",
    "filename_output=\"${filename%.*}_info.txt\"\n",
    "\n",
    "echo -e \"FILENAME: $filename \\nNB LINES: $(wc -l < $archivo) \\nCOLUMNS (name/max-longuer) :\" > $filename_output\n",
    "\n",
    "awk -F$separator '\n",
    "NR == 1 { \n",
    "    # Save columns names in an array\n",
    "    for(i=1; i<=NF; i++) {\n",
    "        nombres[i] = $i\n",
    "        max_len[i] = 0\n",
    "    }\n",
    "}\n",
    "NR > 1 { \n",
    "    # Calculate the longuer max of each column\n",
    "    for(i=1; i<=NF; i++) {\n",
    "        if($i != \"\\\\N\") { \n",
    "            len = length($i)\n",
    "            if(len > max_len[i]) max_len[i] = len\n",
    "        }\n",
    "    }\n",
    "}\n",
    "END {\n",
    "    # Print names columns and longuer max\n",
    "    for(i=1; i<=length(nombres); i++) {\n",
    "        print \"  \"nombres[i] \"\\t\" max_len[i]\n",
    "    }\n",
    "}\n",
    "' \"$archivo\" >> \"${filename_output}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c1d73c-1f75-4ed5-8ec6-09edfb57b215",
   "metadata": {},
   "source": [
    "### **Using the script bash `info_file.sh`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736188f-0fbd-4172-8dbf-7c8af0cec3e2",
   "metadata": {},
   "source": [
    "```sh\n",
    "$./info_file -s \"<separator>\" f <file_path> \n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a06ff724-1131-4d9e-9180-0acb6a85aa77",
   "metadata": {},
   "source": [
    "FILENAME: title.episode.tsv \n",
    "NB LINES: 8695672 \n",
    "COLUMNS (name/max-longuer) :\n",
    "  tconst\t10\n",
    "  parentTconst\t10\n",
    "  seasonNumber\t4\n",
    "  episodeNumber\t5\n",
    "\n",
    "FILENAME: title.akas.tsv \n",
    "NB LINES: 50749729 \n",
    "COLUMNS (name/max-longuer) :\n",
    "  titleId\t10\n",
    "  ordering\t3\n",
    "  title\t831\n",
    "  region\t4\n",
    "  language\t3\n",
    "  types\t20\n",
    "  attributes\t62\n",
    "  isOriginalTitle\t1\n",
    "\n",
    "FILENAME: title.principals.tsv \n",
    "NB LINES: 89828160 \n",
    "COLUMNS (name/max-longuer) :\n",
    "  tconst\t10\n",
    "  ordering\t2\n",
    "  nconst\t10\n",
    "  category\t19\n",
    "  job\t290\n",
    "  characters\t463\n",
    "\n",
    "FILENAME: title.crew.tsv \n",
    "NB LINES: 11317485 \n",
    "COLUMNS (name/max-longuer) :\n",
    "  tconst\t10\n",
    "  directors\t5226\n",
    "  writers\t13853\n",
    "\n",
    "FILENAME: name.basics.tsv \n",
    "NB LINES: 14035382 \n",
    "COLUMNS (name/max-longuer) :\n",
    "  nconst\t10\n",
    "  primaryName\t105\n",
    "  birthYear\t4\n",
    "  deathYear\t4\n",
    "  primaryProfession\t66\n",
    "  knownForTitles\t43\n",
    "\n",
    "FILENAME: title.basics.tsv \n",
    "NB LINES: 11294959 \n",
    "COLUMNS (name/max-longuer) :\n",
    "  tconst\t10\n",
    "  titleType\t12\n",
    "  primaryTitle\t419\n",
    "  originalTitle\t419\n",
    "  isAdult\t1\n",
    "  startYear\t4\n",
    "  endYear\t4\n",
    "  runtimeMinutes\t5\n",
    "  genres\t32\n",
    "\n",
    "FILENAME: title.ratings.tsv \n",
    "NB LINES: 1513042 \n",
    "COLUMNS (name/max-longuer) :\n",
    "  tconst\t10\n",
    "  averageRating\t4\n",
    "  numVotes\t7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cbf71a-8066-4d6d-bf4d-0e9825c20a15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **CREATION BDD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "455c8631-0b8d-4628-9872-09a1eb02f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "\n",
    "\n",
    "sqlite3_db = \"../Database/movies_recommendation.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c26459-a7ce-4a6f-b637-6dd515d19870",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **MCD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef386958-4d04-408d-bd69-12e62f5aeca4",
   "metadata": {},
   "source": [
    "![mcd movies recommendation](https://imgur.com/ebnbvQi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dae179-76fc-41d4-9339-b29a234b8c2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **MLD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a5cae-12a9-4f78-8375-b825c75997b8",
   "metadata": {},
   "source": [
    "![mld movies recommendation](https://imgur.com/Rkwz1nB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3f083-a739-415f-81a5-2622e4b7cb0e",
   "metadata": {},
   "source": [
    "### **SCRIPT SQLITE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79662848-78c3-4943-bb28-1ea8b86de242",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite3_script = \"\"\"\n",
    "------------------------------------------------------------\n",
    "--        Script SQLite  \n",
    "------------------------------------------------------------\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Region\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Region(\n",
    "\tregion_id      INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\tregion_name    TEXT NOT NULL ,\n",
    "\tregion_code    TEXT NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Language\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Language(\n",
    "\tlanguage_id      INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\tlanguage_name    TEXT NOT NULL ,\n",
    "\tlanguage_code    TEXT NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Type\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Type(\n",
    "\ttype_id      INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\ttype_name    TEXT NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Genre\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Genre(\n",
    "\tgenre_id      INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\tgenre_name    TEXT NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Person\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Person(\n",
    "\tperson_Id       TEXT NOT NULL ,\n",
    "\tprimary_name    TEXT ,\n",
    "\tbirth_year      INTEGER ,\n",
    "\tdeath_year      INTEGER,\n",
    "\tCONSTRAINT Person_PK PRIMARY KEY (person_Id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Profession\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Profession(\n",
    "\tprofession_id      INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\tprofession_name    TEXT NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Production_company\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Production_company(\n",
    "\tproduction_company_id      INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\tproduction_company_name    TEXT NOT NULL ,\n",
    "\tregion_id                  INTEGER NOT NULL\n",
    "\n",
    "\t,CONSTRAINT Production_company_Region_FK FOREIGN KEY (region_id) REFERENCES Region(region_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Format\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Format(\n",
    "\tformat_id      INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\tformat_name    TEXT NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Title\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Title(\n",
    "\ttitle_id          TEXT NOT NULL ,\n",
    "\toriginal_title    TEXT,\n",
    "\tprimary_title     TEXT,\n",
    "\tis_adult          INTEGER ,\n",
    "\tstart_year        INTEGER ,\n",
    "\tend_year          INTEGER ,\n",
    "\tbudget            INTEGER ,\n",
    "\trevenue           INTEGER ,\n",
    "\toverview          TEXT,\n",
    "\truntime           INTEGER,\n",
    "\tformat_id         INTEGER,\n",
    "\tCONSTRAINT Title_PK PRIMARY KEY (title_id)\n",
    "\n",
    "\t,CONSTRAINT Title_Format_FK FOREIGN KEY (format_id) REFERENCES Format(format_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Episode\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Episode(\n",
    "\tepisode_id        TEXT NOT NULL ,\n",
    "\tseason_number     INTEGER ,\n",
    "\tepisode_number    INTEGER ,\n",
    "\ttitle_id          TEXT NOT NULL,\n",
    "\tCONSTRAINT Episode_PK PRIMARY KEY (episode_id)\n",
    "\n",
    "\t,CONSTRAINT Episode_Title_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Regional_Title\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Regional_Title(\n",
    "\tregional_title_id    INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\tregional_title       TEXT,\n",
    "\tis_original_title    INTEGER ,\n",
    "\tregion_id            INTEGER ,\n",
    "\tlanguage_id          INTEGER ,\n",
    "\ttitle_id             TEXT NOT NULL\n",
    "\n",
    "\t,CONSTRAINT Regional_Title_Region_FK FOREIGN KEY (region_id) REFERENCES Region(region_id)\n",
    "\t,CONSTRAINT Regional_Title_Language0_FK FOREIGN KEY (language_id) REFERENCES Language(language_id)\n",
    "\t,CONSTRAINT Regional_Title_Title1_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Rating\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Rating(\n",
    "\trating_id         INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\n",
    "\taverage_rating    REAL ,\n",
    "\tnum_votes         INTEGER ,\n",
    "\ttitle_id          TEXT NOT NULL\n",
    "\n",
    "\t,CONSTRAINT Rating_Title_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Types_of_title\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Types_of_title(\n",
    "\ttype_id     INTEGER NOT NULL ,\n",
    "\ttitle_id    TEXT NOT NULL,\n",
    "\tCONSTRAINT Types_of_title_PK PRIMARY KEY (type_id,title_id)\n",
    "\n",
    "\t,CONSTRAINT Types_of_title_Type_FK FOREIGN KEY (type_id) REFERENCES Type(type_id)\n",
    "\t,CONSTRAINT Types_of_title_Title0_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Genres_of_title\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Genres_of_title(\n",
    "\ttitle_id    TEXT NOT NULL,\n",
    "\tgenre_id    INTEGER NOT NULL,\n",
    "\tCONSTRAINT Genres_of_title_PK PRIMARY KEY (title_id,genre_id)\n",
    "\n",
    "\t,CONSTRAINT Genres_of_title_Title_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    "\t,CONSTRAINT Genres_of_title_Genre0_FK FOREIGN KEY (genre_id) REFERENCES Genre(genre_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Crew\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Crew(\n",
    "    crew_id           INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n",
    "\ttitle_id          TEXT NOT NULL ,\n",
    "\tperson_Id         TEXT NOT NULL ,\n",
    "\tprofession_id     INTEGER NOT NULL\n",
    "\n",
    "\t,CONSTRAINT Crew_Title_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    "\t,CONSTRAINT Crew_Person0_FK FOREIGN KEY (person_Id) REFERENCES Person(person_Id)\n",
    "\t,CONSTRAINT Crew_Profession1_FK FOREIGN KEY (profession_id) REFERENCES Profession(profession_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Title_by_production_company\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Title_by_production_company(\n",
    "\ttitle_id                 TEXT NOT NULL ,\n",
    "\tproduction_company_id    INTEGER NOT NULL,\n",
    "\tCONSTRAINT Title_by_production_company_PK PRIMARY KEY (title_id,production_company_id)\n",
    "\n",
    "\t,CONSTRAINT Title_by_production_company_Title_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    "\t,CONSTRAINT Title_by_production_company_Production_company0_FK FOREIGN KEY (production_company_id) REFERENCES Production_company(production_company_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Spoken_languages_in_title\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Spoken_languages_in_title(\n",
    "\ttitle_id       TEXT NOT NULL ,\n",
    "\tlanguage_id    INTEGER NOT NULL,\n",
    "\tCONSTRAINT Spoken_languages_in_title_PK PRIMARY KEY (title_id,language_id)\n",
    "\n",
    "\t,CONSTRAINT Spoken_languages_in_title_Title_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    "\t,CONSTRAINT Spoken_languages_in_title_Language0_FK FOREIGN KEY (language_id) REFERENCES Language(language_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Title_production_region\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Title_production_region(\n",
    "\tregion_id    INTEGER NOT NULL ,\n",
    "\ttitle_id     TEXT NOT NULL,\n",
    "\tCONSTRAINT Title_production_region_PK PRIMARY KEY (region_id,title_id)\n",
    "\n",
    "\t,CONSTRAINT Title_production_region_Region_FK FOREIGN KEY (region_id) REFERENCES Region(region_id)\n",
    "\t,CONSTRAINT Title_production_region_Title0_FK FOREIGN KEY (title_id) REFERENCES Title(title_id)\n",
    ");\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "-- Table: Top_3_Professions\n",
    "------------------------------------------------------------\n",
    "CREATE TABLE Top_3_Professions(\n",
    "\tprofession_id    INTEGER NOT NULL ,\n",
    "\tperson_Id        TEXT NOT NULL,\n",
    "\tCONSTRAINT Top_3_Professions_PK PRIMARY KEY (profession_id,person_Id)\n",
    "\n",
    "\t,CONSTRAINT Top_3_Professions_Profession_FK FOREIGN KEY (profession_id) REFERENCES Profession(profession_id)\n",
    "\t,CONSTRAINT Top_3_Professions_Person0_FK FOREIGN KEY (person_Id) REFERENCES Person(person_Id)\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5a510-d41e-45b7-a511-cd8432e99eb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **SCRIPT MYSQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a8246-fbeb-4c4e-8774-06f8793b17bc",
   "metadata": {},
   "source": [
    "### **CREATION SQLITE DATABASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "535b1654-03c1-4fd4-922f-326c58cda78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBB Created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = sql.connect(sqlite3_db)\n",
    "    conn.executescript(sqlite3_script)\n",
    "    print(\"DBB Created\")\n",
    "except Exception as exception:\n",
    "    print(exception)\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d6de5-e7c2-438b-a40f-25994ff8dbfa",
   "metadata": {},
   "source": [
    "## **CODING : FROM FILE TO SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85a606e5-84fc-44e7-baa8-89380f9426ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import mysql.connector\n",
    "\n",
    "csv.field_size_limit(100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cbd709-b64d-4402-82e0-309db149567f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **`TypeOfTable` Enum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67679173-5701-49ff-a4db-4a2c37a9ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "@unique\n",
    "class TypeOfTable(StrEnum):\n",
    "    REGULAR = auto()\n",
    "    FLAT = auto()\n",
    "    SIMPLE_JOIN = auto()\n",
    "    MULTI_JOIN = auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f41afc-0535-4085-a433-38ebb9813588",
   "metadata": {},
   "source": [
    "#### **`SQLiteDatabase` Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd7ea4e5-0e5e-4751-a36e-a8e986de39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite database handler class\n",
    "class SQLiteDatabase:\n",
    "    def __init__(self, db_name):\n",
    "        self.db_name = db_name\n",
    "        self.connection = self._create_connection()\n",
    "\n",
    "    def _create_connection(self):\n",
    "        \"\"\"Establishes a connection to the SQLite database.\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_name)\n",
    "            return conn\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error connecting to SQLite database: {e}\")\n",
    "            return None\n",
    "\n",
    "    def insert_records(self, chunk, columns, table_name):\n",
    "        \"\"\"Inserts records into the SQLite database in bulk.\"\"\"\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            placeholders = ', '.join([f\":{col}\" for col in columns])\n",
    "            query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "            cursor.executemany(query, chunk)\n",
    "            self.connection.commit()\n",
    "            print(f\"Inserted records into SQLite table '{table_name}'.\")\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error inserting data into SQLite database: {e}\")\n",
    "            self.connection.rollback()\n",
    "    \n",
    "    def update_records(self, chunk, table_name, condition_columns, columns_to_update, condition_operator: str=\"AND\"):\n",
    "        \"\"\"Updates records in the SQLite database in bulk using prepared statements.\"\"\"\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            condition_operator = condition_operator if condition_operator in [\"AND\", \"OR\"] else \"\"\n",
    "            set_clause = ', '.join([f\"{col} = :{col}\" for col in columns_to_update])\n",
    "            condition_columns_placeholder = f\" {condition_operator} \".join(\n",
    "                f\"{condition_column} = :{condition_column}\"\n",
    "                for condition_column in condition_columns\n",
    "            )\n",
    "            query = f\"UPDATE {table_name} SET {set_clause} WHERE {condition_columns_placeholder}\"\n",
    "            cursor.executemany(query, chunk)\n",
    "            self.connection.commit()\n",
    "            print(f\"Updated records in {table_name} with condition on '{', '.join(condition_columns)}'.\")\n",
    "            \n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error updating records in SQLite database: {e}\")\n",
    "            self.connection.rollback()\n",
    "\n",
    "    def fetch_records(self, table_name, columns: List = [], condition=None):\n",
    "        \"\"\"Fetches records from a table.\"\"\"\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            columns = \",\".join(columns) if len(columns) > 0 else \"*\"\n",
    "            query = f\"SELECT {columns} FROM {table_name}\"\n",
    "            if condition:\n",
    "                query += f\" WHERE {condition}\"\n",
    "            cursor.execute(query)\n",
    "            records = cursor.fetchall()\n",
    "            return records\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error fetching data from SQLite database: {e}\")\n",
    "            return []\n",
    "    def fetch_one_record(self, table_name, columns: List = [], conditions: Dict = {}, condition_operator: str=\"AND\"):\n",
    "        \"\"\"Fetches records from a table.\"\"\"\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            condition_operator = condition_operator if condition_operator in [\"AND\", \"OR\"] else \"\"\n",
    "            condition_placeholder = f\" {condition_operator} \".join(\n",
    "                f\"{condition_column} = :{condition_column}\"\n",
    "                for condition_column in conditions.keys()\n",
    "            )\n",
    "            columns = \",\".join(columns) if len(columns) > 0 else \"*\"\n",
    "            query = f\"SELECT {columns} FROM {table_name}\"\n",
    "            if len(condition_placeholder) > 0:\n",
    "                query += f\" WHERE {condition_placeholder}\"\n",
    "\n",
    "            cursor.execute(query, conditions)\n",
    "            record = cursor.fetchone()\n",
    "            return record\n",
    "            \n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error fetching data from SQLite database: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Closes the connection to the SQLite database.\"\"\"\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "            print(\"SQLite database connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72ec823-fdde-42d4-98ae-a4695f371de8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **`MySQLDatabase` Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b243e8d9-ba52-44ef-a2c0-8fc82f1c66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL database handler class\n",
    "class MySQLDatabase:\n",
    "    def __init__(self, host, user, password, database):\n",
    "        self.host = host\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.database = database\n",
    "        self.connection = self._create_connection()\n",
    "\n",
    "    def _create_connection(self):\n",
    "        \"\"\"Establishes a connection to the MySQL database.\"\"\"\n",
    "        try:\n",
    "            conn = mysql.connector.connect(\n",
    "                host=self.host,\n",
    "                user=self.user,\n",
    "                password=self.password,\n",
    "                database=self.database\n",
    "            )\n",
    "            return conn\n",
    "        except mysql.connector.Error as e:\n",
    "            print(f\"Error connecting to MySQL database: {e}\")\n",
    "            return None\n",
    "\n",
    "    def insert_records(self, table_name, columns, data):\n",
    "        \"\"\"Inserts records into the MySQL database in bulk.\"\"\"\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            placeholders = ', '.join(['%s'] * len(columns))  # Parametrization for MySQL\n",
    "            query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "            cursor.executemany(query, data)\n",
    "            self.connection.commit()\n",
    "            print(f\"Inserted records into MySQL table '{table_name}'.\")\n",
    "        except mysql.connector.Error as e:\n",
    "            print(f\"Error inserting data into MySQL database: {e}\")\n",
    "            self.connection.rollback()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Closes the connection to the MySQL database.\"\"\"\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "            print(\"MySQL database connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63491b6-ce1b-4fa9-af42-a6610b2d9fba",
   "metadata": {},
   "source": [
    "#### **`FileProcessor` Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da045e84-9255-4f59-9023-b5ff3377c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileProcessor:\n",
    "    def __init__(self, file_path, delimiter):\n",
    "        self.file_path = file_path\n",
    "        self.delimiter = delimiter  # The specified delimiter\n",
    "\n",
    "    def read_in_chunks(self, columns, referenced_columns = [], rows_with_list = False, chunk_size=10000):\n",
    "        \"\"\"Reads the file in chunks and returns the cleaned data.\"\"\"\n",
    "        try:\n",
    "            with open(self.file_path, newline='', encoding='utf-8') as f:\n",
    "                reader = csv.DictReader(f, delimiter=self.delimiter)\n",
    "                chunk = []\n",
    "                size = len(columns) + len(referenced_columns)\n",
    "                for row in reader:\n",
    "                    row_to_dict = {}\n",
    "                    row_to_dict.update(self.__row_to_dict(row, columns))\n",
    "                    row_to_dict.update(self.__row_to_dict(row, referenced_columns, False))\n",
    "                    if rows_with_list:\n",
    "                        row_list = [[{key:value}] for key, value in row_to_dict.items() if not isinstance(value, list) and value is not None]\n",
    "                        row_list += [[{key:value} for value in values if value is not None] for key, values in row_to_dict.items() if isinstance(values, list)]\n",
    "                        if len(row_list) == size:\n",
    "                            row_list = get_cartesian_product(row_list)\n",
    "                            chunk.extend(row_list)\n",
    "                    else:\n",
    "                        chunk.append(row_to_dict)\n",
    "                    if len(chunk) >= chunk_size:\n",
    "                        yield chunk\n",
    "                        chunk = []\n",
    "                if chunk:\n",
    "                    yield chunk\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: File not found: {e}\")\n",
    "            raise\n",
    "        except csv.Error as e:\n",
    "            print(f\"Error reading the file: {e}\")\n",
    "            raise\n",
    "\n",
    "    def __row_to_dict(self, row, columns, are_regular: bool=True, column_types: List = [str, int, float, bool, list]) -> Dict:\n",
    "\n",
    "        row_like_dict = {}\n",
    "        if are_regular:\n",
    "            row_like_dict = {\n",
    "                col[\"column_in_table\"]: clean_value(row[col[\"column_in_file\"]], value_type=col[\"column_type\"])\n",
    "                for col in columns\n",
    "                if col[\"column_type\"] in column_types\n",
    "            }\n",
    "        else:\n",
    "            for col in columns:\n",
    "                key = col.get(\"column_in_final_table\", None)\n",
    "                default_value = col.get(\"default_value\", None)\n",
    "                value_in_file = None\n",
    "                value = None\n",
    "                referenced_values = col.get(\"column_values\", [])\n",
    "                \n",
    "                if key:\n",
    "                    if default_value:\n",
    "                        value = referenced_values.get(default_value, None)\n",
    "                    else:\n",
    "                        if col[\"column_type\"] in column_types:\n",
    "                            value_in_file = clean_value(row[col[\"column_in_file\"]], value_type=col[\"column_type\"])\n",
    "        \n",
    "                        if isinstance(value_in_file, list) :\n",
    "                            value_list = []\n",
    "                            for val in value_in_file:\n",
    "                                val = clean_value(val, value_type=col.get('type_if_list',str))\n",
    "                                value_list.append(referenced_values.get(val, None))\n",
    "                            value = value_list    \n",
    "                        elif value_in_file:\n",
    "                            value = referenced_values.get(value_in_file, None)\n",
    "                    \n",
    "                    row_like_dict[key] = value\n",
    "        return row_like_dict\n",
    "\n",
    "        \n",
    "    \n",
    "    def extract_unique_column_values(self, column_info):\n",
    "        \"\"\"Extracts and cleans unique values from a column in the file.\"\"\"\n",
    "        column_name_in_file = column_info[\"column_in_file\"]\n",
    "        db_column_name = column_info[\"column_in_table\"]\n",
    "        data_type = column_info[\"column_type\"]\n",
    "        unique_values = set()\n",
    "\n",
    "        try:\n",
    "            with open(self.file_path, newline='', encoding='utf-8') as f:\n",
    "                reader = csv.DictReader(f, delimiter=self.delimiter)\n",
    "\n",
    "                for row in reader:\n",
    "                    value = row[column_name_in_file]\n",
    "                    cleaned_value = clean_value(value, value_type=data_type)\n",
    "\n",
    "                    if isinstance(cleaned_value, list):\n",
    "                        # If the value is a list, clean its items with the specified type in \"type_if_list\"\n",
    "                        type_if_list = column_info.get(\"type_if_list\", str)  # Use \"type_if_list\" if provided\n",
    "                        for item in cleaned_value:\n",
    "                            cleaned_item = clean_value(item, value_type=type_if_list)\n",
    "                            if cleaned_item is not None:\n",
    "                                unique_values.add(cleaned_item)\n",
    "                    elif cleaned_value is not None:\n",
    "                        unique_values.add(cleaned_value)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: File not found: {e}\")\n",
    "            raise\n",
    "        except csv.Error as e:\n",
    "            print(f\"Error reading the file: {e}\")\n",
    "            raise\n",
    "\n",
    "        return [{db_column_name: value} for value in unique_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403f461-cbc6-47b1-9103-cfa659ba48e2",
   "metadata": {},
   "source": [
    "#### **`DataProcessor` Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef8e9645-d6f2-4d7e-a07b-51d75cbda830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, sqlite_connection, mysql_connection):\n",
    "        \"\"\"\n",
    "        :param sqlite_connection: Connection object for SQLite\n",
    "        :param mysql_connection: Connection object for MySQL\n",
    "        \"\"\"\n",
    "        self.db = sqlite_connection  # SQLite connection\n",
    "        self.mysql_db = mysql_connection  # MySQL connection\n",
    "\n",
    "    def process_flat_tables(self, flat_tables_info):\n",
    "        \"\"\"Process each table and insert data as per the columns information.\"\"\"\n",
    "\n",
    "        for table_info in flat_tables_info:\n",
    "            table_name = table_info[\"table_name\"]  \n",
    "            tsv_file = table_info[\"path_file\"]\n",
    "            delimiter = table_info[\"delimiter\"]\n",
    "            columns = table_info[\"columns\"]\n",
    "            unique_values = table_info[\"unique_values\"] \n",
    "            \n",
    "            print(f\"Processing table: {table_name}\")\n",
    "\n",
    "            if unique_values:\n",
    "                # If unique_values is True, insert only unique values\n",
    "                self.__insert_unique_values(table_name, tsv_file, delimiter, columns)\n",
    "            else:\n",
    "                # If unique_values is False, process all values\n",
    "                self.__process_and_insert_data(table_name, tsv_file, delimiter, columns)\n",
    "\n",
    "    def process_regular_tables(self, regular_tables_info):\n",
    "        for table_info in regular_tables_info:\n",
    "            table_name = table_info[\"table_name\"]  \n",
    "            file = table_info[\"path_file\"]\n",
    "            delimiter = table_info[\"delimiter\"]\n",
    "            referenced_columns = table_info.get(\"referenced_columns\", [])\n",
    "            regular_columns = table_info[\"columns\"]\n",
    "            referenced_columns_with_values = []\n",
    "\n",
    "            print(f\"Processing table: {table_name}\") \n",
    "            \n",
    "            for column in referenced_columns:\n",
    "                table_to_use = column['table_to_use']\n",
    "                ref = column['columns_of_reference']\n",
    "                column_values = {value : id \n",
    "                                 for value, id in self.db.fetch_records(\n",
    "                                     table_to_use, [ref['column_in_table'],\n",
    "                                                    ref['column_id_in_table']])\n",
    "                                }\n",
    "                ref[\"column_values\"] = column_values\n",
    "                ref[\"column_in_final_table\"] = column['column_in_table']\n",
    "                referenced_columns_with_values.append(ref)\n",
    "            self.__process_and_insert_regular_tables(table_name, file, delimiter, regular_columns, referenced_columns_with_values)\n",
    "\n",
    "\n",
    "    def process_join_tables(self, join_tables_info):\n",
    "        for table_info in join_tables_info:\n",
    "            table_name = table_info[\"table_name\"]  \n",
    "            file = table_info[\"path_file\"]\n",
    "            delimiter = table_info[\"delimiter\"]\n",
    "            referenced_columns = table_info.get(\"referenced_columns\", [])\n",
    "            regular_columns = table_info[\"columns\"]\n",
    "            referenced_columns_with_values = []\n",
    "            print(f\"Processing table: {table_name}\") \n",
    "            \n",
    "            for column in referenced_columns:\n",
    "                table_to_use = column['table_to_use']\n",
    "                default_value = column.get(\"default_value\", None)\n",
    "                ref = column['columns_of_reference']\n",
    "                if default_value:\n",
    "                    default_value = clean_value(default_value)\n",
    "                    record = self.db.fetch_one_record(table_to_use,\n",
    "                                                         [ref['column_in_table'],ref['column_id_in_table']],\n",
    "                                                         {ref['column_in_table']:default_value})\n",
    "                    if record:\n",
    "                        value, id = record\n",
    "                        column_values = {value : id}\n",
    "                        ref[\"default_value\"] = default_value\n",
    "                    else:\n",
    "                        print(f\"The default_value {default_value} for the column {column} don't exists in the DB \")\n",
    "                        raise sqlite3.Error\n",
    "                        \n",
    "                else:\n",
    "                    column_values = {value : id \n",
    "                                     for value, id in self.db.fetch_records(\n",
    "                                         table_to_use, [ref['column_in_table'],\n",
    "                                                        ref['column_id_in_table']])\n",
    "                                }\n",
    "                ref[\"column_values\"] = column_values\n",
    "                ref[\"column_in_final_table\"] = column['column_in_table']\n",
    "                referenced_columns_with_values.append(ref)\n",
    "            self.__process_and_insert_join_tables(table_name, file, delimiter, regular_columns, referenced_columns_with_values)\n",
    "\n",
    "    def process_update_tables(self, tables_to_update_info):\n",
    "        for table_info in tables_to_update_info:\n",
    "            table_name = table_info[\"table_name\"]  \n",
    "            file = table_info[\"path_file\"]\n",
    "            delimiter = table_info[\"delimiter\"]\n",
    "            condition_columns = table_info[\"columns_for_condition\"]\n",
    "            regular_columns = table_info.get(\"columns\",[])\n",
    "            referenced_columns = table_info.get(\"referenced_columns\",[])\n",
    "            referenced_columns_with_values = []\n",
    "            \n",
    "            if len(condition_columns) > 0 and (len(regular_columns) + len(referenced_columns)) > 0:\n",
    "                print(f\"Processing table: {table_name}\") \n",
    "                \n",
    "                for column in referenced_columns:\n",
    "                    table_to_use = column['table_to_use']\n",
    "                    ref = column['columns_of_reference']\n",
    "                    column_values = {value : id \n",
    "                                     for value, id in self.db.fetch_records(\n",
    "                                         table_to_use, [ref['column_in_table'],\n",
    "                                                        ref['column_id_in_table']])\n",
    "                                    }\n",
    "                    ref[\"column_values\"] = column_values\n",
    "                    ref[\"column_in_final_table\"] = column['column_in_table']\n",
    "                    referenced_columns_with_values.append(ref)\n",
    "                \n",
    "                self.__process_to_update_tables(table_name, file, delimiter, condition_columns, regular_columns, referenced_columns_with_values)\n",
    "            else:\n",
    "                print(f\"You need 'columns for condition' for update the table <<{table_name}>>\")\n",
    "\n",
    "\n",
    "    def __process_to_update_tables(self, table_name, file, delimiter, condition_columns, regular_columns_to_update, referenced_columns_with_values):\n",
    "        \"\"\"Processes the file and update the data into the SQLite database.\"\"\"\n",
    "        print(f\"Processing and update data into SQLite table '{table_name}' from {file}\")\n",
    "        \n",
    "        file_processor = FileProcessor(file, delimiter)\n",
    "        columns_to_update = []\n",
    "        regular_columns = []\n",
    "        regular_columns.extend(condition_columns)\n",
    "        referenced_columns = []\n",
    "        condition_columns_names = [column[\"column_in_table\"] for column in condition_columns]\n",
    "        if len(regular_columns_to_update) > 0:\n",
    "            columns_to_update.extend([column[\"column_in_table\"] for column in regular_columns_to_update])\n",
    "            regular_columns.extend(regular_columns_to_update)\n",
    "        if len(referenced_columns_with_values) > 0 : \n",
    "            columns_to_update.extend([column[\"column_in_final_table\"] for column in referenced_columns_with_values])\n",
    "            referenced_columns = referenced_columns_with_values\n",
    "        \n",
    "        for chunk in file_processor.read_in_chunks(regular_columns, referenced_columns):\n",
    "            self.db.update_records(chunk, table_name, condition_columns_names, columns_to_update)\n",
    "    \n",
    "    def __process_and_insert_join_tables(self, table_name, file, delimiter, regular_columns, referenced_columns):\n",
    "        \"\"\"Processes the file and inserts the data into the SQLite database.\"\"\"\n",
    "        print(f\"Processing and inserting data into SQLite table '{table_name}' from {file}\")\n",
    "        \n",
    "        file_processor = FileProcessor(file, delimiter)\n",
    "        columns_in_table = []\n",
    "        if len(regular_columns) > 0:\n",
    "            columns_in_table.extend([column[\"column_in_table\"] for column in regular_columns])\n",
    "        if len(referenced_columns) > 0 : \n",
    "            columns_in_table.extend([column[\"column_in_final_table\"] for column in referenced_columns])\n",
    "        for chunk in file_processor.read_in_chunks(regular_columns, referenced_columns, rows_with_list=True):\n",
    "            self.db.insert_records(chunk, columns_in_table, table_name)\n",
    "\n",
    "    \n",
    "    def __process_and_insert_regular_tables(self, table_name, file, delimiter, regular_columns, referenced_columns):\n",
    "        \"\"\"Processes the file and inserts the data into the SQLite database.\"\"\"\n",
    "        print(f\"Processing and inserting data into SQLite table '{table_name}' from {file}\")\n",
    "        file_processor = FileProcessor(file, delimiter)\n",
    "        columns_in_table = [column[\"column_in_table\"] for column in regular_columns]\n",
    "        \n",
    "        if len(referenced_columns) > 0 : \n",
    "            columns_in_table.extend([column[\"column_in_final_table\"] for column in referenced_columns])\n",
    "    \n",
    "        for chunk in file_processor.read_in_chunks(regular_columns, referenced_columns):\n",
    "            self.db.insert_records(chunk, columns_in_table, table_name)\n",
    "    \n",
    "    def __process_and_insert_data(self, table_name, tsv_file, delimiter, columns):\n",
    "        \"\"\"Processes the file and inserts the data into the SQLite database.\"\"\"\n",
    "        print(f\"Processing and inserting data into SQLite table '{table_name}' from {tsv_file}\")\n",
    "        \n",
    "        file_processor = FileProcessor(tsv_file, delimiter)\n",
    "        columns_db = [column[\"column_in_table\"] for column in columns]\n",
    "        for chunk in file_processor.read_in_chunks(columns):      \n",
    "            self.db.insert_records(chunk, columns_db, table_name)\n",
    "\n",
    "    def __insert_unique_values(self, table_name, tsv_file, delimiter, columns):\n",
    "        \"\"\"Extracts and inserts unique values from a column into SQLite.\"\"\"\n",
    "        print(f\"Inserting unique values into SQLite table '{table_name}' from {tsv_file}\")\n",
    "\n",
    "        # Assuming `columns` contains only one dictionary with the structure for unique values\n",
    "        column_info = columns  # Here we take the first item, which is the only one for unique values\n",
    "        file_processor = FileProcessor(tsv_file, delimiter)\n",
    "        unique_values = file_processor.extract_unique_column_values(column_info)\n",
    "\n",
    "        if unique_values:\n",
    "            self.db.insert_records(unique_values, [column_info[\"column_in_table\"]], table_name)\n",
    "\n",
    "    def transfer_data_to_mysql(self, table_name):\n",
    "        \"\"\"Transfers data from SQLite to MySQL.\"\"\"\n",
    "        try:\n",
    "            cursor = self.db.connection.cursor()\n",
    "            query = f\"SELECT * FROM {table_name}\"\n",
    "            cursor.execute(query)\n",
    "            rows = cursor.fetchall()\n",
    "\n",
    "            # Insert the data into MySQL\n",
    "            # TO DO\n",
    "            print(f\"Data transferred from SQLite to MySQL for table '{table_name}'.\")\n",
    "\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error reading from SQLite: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during data transfer: {e}\")\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Closes the connections to both databases.\"\"\"\n",
    "        if self.db:\n",
    "            self.db.close()\n",
    "            print(\"SQLite database connection closed.\")\n",
    "        if self.mysql_db:\n",
    "            self.mysql_db.close()\n",
    "            print(\"MySQL database connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5352bdbc-6f05-4399-a048-afbb6fbd8844",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Structure for flat tables `flat_tables_info`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919a051-0c70-4c70-a8c5-cbadf05ea944",
   "metadata": {},
   "source": [
    "The order is very important for insertion in database because there are constraints in the tables.\n",
    "\n",
    "```json\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"table_name\": <table_name_in_db>,  \n",
    "        \"path_file\": <path_file>,\n",
    "        \"delimiter\": <delimiter>,  # Delimiter of the file\n",
    "        \"columns\": [\n",
    "            {\n",
    "                \"column_in_file\": <field_name_in_file>,\n",
    "                \"column_in_table\": <field_name_in_db>,\n",
    "                \"column_type\": <primitive_python_type_or_list>,\n",
    "                \"type_if_list\": <primitive_python_type>\n",
    "            },\n",
    "            {\n",
    "                \"column_in_file\": \"name\",\n",
    "                \"column_in_table\": \"name\",\n",
    "                \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "                \"column_in_file\": \"age\",\n",
    "                \"column_in_table\": \"age\",\n",
    "                \"column_type\": int\n",
    "            }\n",
    "        ],\n",
    "        \"unique_values\": False \n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"Subjects\",\n",
    "        \"path_file\": \"../data/subjects.csv\",\n",
    "        \"delimiter\": \",\",\n",
    "        \"columns\":{\n",
    "                \"column_in_file\": \"subjects\",\n",
    "                \"column_in_table\": \"suject\",\n",
    "                \"column_type\": list,\n",
    "                \"type_if_list\": str\n",
    "            }\n",
    "        ,\n",
    "        \"unique_values\": True  // If only one column and the values in the column are unique\n",
    "    }\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b318d0f-4f9b-4f69-88f7-5a532cbcf86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c798011-70f8-458e-ad2d-423d1d531e4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **`flat_tables_info`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe57a13f-1cb2-4434-a5b8-ecd0ab456737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of dictionaries\n",
    "flat_tables_info = [\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/title.basics.tsv',\n",
    "        \"table_name\": 'Genre',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":{\n",
    "            \"column_in_file\": \"genres\",\n",
    "            \"column_in_table\": \"genre_name\",\n",
    "            \"column_type\": list,\n",
    "            \"type_if_list\": str\n",
    "        },\n",
    "        \"unique_values\": True\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/titles_types.csv',\n",
    "        \"table_name\": 'Type',\n",
    "        \"delimiter\": \",\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"id\",\n",
    "            \"column_in_table\": \"type_id\",\n",
    "            \"column_type\": int\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"type\",\n",
    "            \"column_in_table\": \"type_name\",\n",
    "            \"column_type\": str,\n",
    "            }\n",
    "            \n",
    "        ],\n",
    "        \"unique_values\": False\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/title.basics.tsv',\n",
    "        \"table_name\": 'Format',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":{\n",
    "            \"column_in_file\": \"titleType\",\n",
    "            \"column_in_table\": \"format_name\",\n",
    "            \"column_type\": str\n",
    "            },\n",
    "        \"unique_values\": True\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/regions-codes.csv',\n",
    "        \"table_name\": 'Region',\n",
    "        \"delimiter\": \",\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"code\",\n",
    "            \"column_in_table\": \"region_code\",\n",
    "            \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"country\",\n",
    "            \"column_in_table\": \"region_name\",\n",
    "            \"column_type\": str,\n",
    "            }\n",
    "            \n",
    "        ],\n",
    "        \"unique_values\": False\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/language-codes.csv',\n",
    "        \"table_name\": 'Language',\n",
    "        \"delimiter\": \",\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"code\",\n",
    "            \"column_in_table\": \"language_code\",\n",
    "            \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"name\",\n",
    "            \"column_in_table\": \"language_name\",\n",
    "            \"column_type\": str,\n",
    "            }\n",
    "        ],\n",
    "        \"unique_values\": False\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/name.basics.tsv',\n",
    "        \"table_name\": 'Profession',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":{\n",
    "            \"column_in_file\": \"primaryProfession\",\n",
    "            \"column_in_table\": \"profession_name\",\n",
    "            \"column_type\": list,\n",
    "            \"type_if_list\": str\n",
    "        },\n",
    "        \"unique_values\": True\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/name.basics.tsv',\n",
    "        \"table_name\": 'Person',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"nconst\",\n",
    "            \"column_in_table\": \"person_id\",\n",
    "            \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"primaryName\",\n",
    "            \"column_in_table\": \"primary_name\",\n",
    "            \"column_type\": str,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"birthYear\",\n",
    "            \"column_in_table\": \"birth_year\",\n",
    "            \"column_type\": int,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"deathYear\",\n",
    "            \"column_in_table\": \"death_year\",\n",
    "            \"column_type\": int,\n",
    "            }\n",
    "        ],\n",
    "        \"unique_values\": False\n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1194ea-2ce3-47b1-8682-e5d50161c297",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **`regular_tables_info`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c4a49561-7be1-4015-a2ad-04d797372084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of dictionaries\n",
    "regular_tables_info = [\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/title.basics.tsv',\n",
    "        \"table_name\": 'Title',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"tconst\",\n",
    "            \"column_in_table\": \"title_id\",\n",
    "            \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"originalTitle\",\n",
    "            \"column_in_table\": \"original_title\",\n",
    "            \"column_type\": str,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"primaryTitle\",\n",
    "            \"column_in_table\": \"primary_title\",\n",
    "            \"column_type\": str,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"isAdult\",\n",
    "            \"column_in_table\": \"is_adult\",\n",
    "            \"column_type\": bool,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"startYear\",\n",
    "            \"column_in_table\": \"start_year\",\n",
    "            \"column_type\": int,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"endYear\",\n",
    "            \"column_in_table\": \"end_year\",\n",
    "            \"column_type\": int,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"runtimeMinutes\",\n",
    "            \"column_in_table\": \"runtime\",\n",
    "            \"column_type\": int,\n",
    "            },\n",
    "        ],\n",
    "        \"referenced_columns\":[\n",
    "            {   \"column_in_table\": \"format_id\",\n",
    "                \"table_to_use\": \"Format\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"format_id\",\n",
    "                    \"column_in_table\" : \"format_name\",\n",
    "                    \"column_in_file\" : \"titleType\",\n",
    "                    \"column_type\" : str\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/title.ratings.tsv',\n",
    "        \"table_name\": 'Rating',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"tconst\",\n",
    "            \"column_in_table\": \"title_id\",\n",
    "            \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"averageRating\",\n",
    "            \"column_in_table\": \"average_rating\",\n",
    "            \"column_type\": str,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"numVotes\",\n",
    "            \"column_in_table\": \"num_votes\",\n",
    "            \"column_type\": int,\n",
    "            }   \n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/title.episode.tsv',\n",
    "        \"table_name\": 'Episode',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"tconst\",\n",
    "            \"column_in_table\": \"episode_id\",\n",
    "            \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"parentTconst\",\n",
    "            \"column_in_table\": \"title_id\",\n",
    "            \"column_type\": str,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"seasonNumber\",\n",
    "            \"column_in_table\": \"season_number\",\n",
    "            \"column_type\": int,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"episodeNumber\",\n",
    "            \"column_in_table\": \"episode_number\",\n",
    "            \"column_type\": int,\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/title.akas.tsv',\n",
    "        \"table_name\": 'Regional_Title',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"titleId\",\n",
    "            \"column_in_table\": \"title_id\",\n",
    "            \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"title\",\n",
    "            \"column_in_table\": \"regional_title\",\n",
    "            \"column_type\": str,\n",
    "            },\n",
    "            {\n",
    "            \"column_in_file\": \"isOriginalTitle\",\n",
    "            \"column_in_table\": \"is_original_title\",\n",
    "            \"column_type\": bool,\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\":[\n",
    "            {   \n",
    "                \"column_in_table\": \"region_id\",\n",
    "                \"table_to_use\": \"Region\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"region_id\",\n",
    "                    \"column_in_table\" : \"region_code\",\n",
    "                    \"column_in_file\" : \"region\",\n",
    "                    \"column_type\" : str\n",
    "                }                 \n",
    "            },\n",
    "            {   \n",
    "                \"column_in_table\": \"language_id\",\n",
    "                \"table_to_use\": \"Language\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"language_id\",\n",
    "                    \"column_in_table\" : \"language_code\",\n",
    "                    \"column_in_file\" : \"language\",\n",
    "                    \"column_type\" : str\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"path_file\": '../Data_Files/data/production_companies.csv',\n",
    "        \"table_name\": 'Production_company',\n",
    "        \"delimiter\": \"|\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "            \"column_in_file\": \"company_name\",\n",
    "            \"column_in_table\": \"production_company_name\",\n",
    "            \"column_type\": str\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\":[\n",
    "            {   \n",
    "                \"column_in_table\": \"region_id\",\n",
    "                \"table_to_use\": \"Region\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"region_id\",\n",
    "                    \"column_in_table\" : \"region_code\",\n",
    "                    \"column_in_file\" : \"region_code\",\n",
    "                    \"column_type\" : str\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20205778-7ed4-482f-b059-5a7c7f13717a",
   "metadata": {},
   "source": [
    "#### **`join_tables_info`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3877b761-4fb8-4161-bc09-0ad50d2fa61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of dictionaries\n",
    "join_tables_info = [\n",
    "    {\n",
    "        \"table_name\": 'Genres_of_title',\n",
    "        \"path_file\": '../Data_Files/data/title.basics.tsv',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"tconst\",\n",
    "                \"column_in_table\": \"title_id\",\n",
    "                \"column_type\": str\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\": [\n",
    "            {   \"column_in_table\": \"genre_id\",\n",
    "                \"table_to_use\": \"Genre\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"genre_id\",\n",
    "                    \"column_in_table\" : \"genre_name\",\n",
    "                    \"column_in_file\" : \"genres\",\n",
    "                    \"column_type\" : list,\n",
    "                    \"type_if_list\": str\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": 'Spoken_languages_in_title',\n",
    "        \"path_file\": '../Data_Files/data/tmdb_full_separator.csv',\n",
    "        \"delimiter\": \"|\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"imdb_id\",\n",
    "                \"column_in_table\": \"title_id\",\n",
    "                \"column_type\": str\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\": [\n",
    "            {   \"column_in_table\": \"language_id\",\n",
    "                \"table_to_use\": \"Language\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"language_id\",\n",
    "                    \"column_in_table\" : \"language_code\",\n",
    "                    \"column_in_file\" : \"spoken_languages\",\n",
    "                    \"column_type\" : list,\n",
    "                    \"type_if_list\": str\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": 'Top_3_Professions',\n",
    "        \"path_file\": '../Data_Files/data/name.basics.tsv',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"nconst\",\n",
    "                \"column_in_table\": \"person_id\",\n",
    "                \"column_type\": str\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\": [\n",
    "            {   \"column_in_table\": \"profession_id\",\n",
    "                \"table_to_use\": \"Profession\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"profession_id\",\n",
    "                    \"column_in_table\" : \"profession_name\",\n",
    "                    \"column_in_file\" : \"primaryProfession\",\n",
    "                    \"column_type\" : list,\n",
    "                    \"type_if_list\": str\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": 'Title_production_region',\n",
    "        \"path_file\": '../Data_Files/data/tmdb_full_separator.csv',\n",
    "        \"delimiter\": \"|\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"imdb_id\",\n",
    "                \"column_in_table\": \"title_id\",\n",
    "                \"column_type\": str\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\": [\n",
    "            {   \"column_in_table\": \"region_id\",\n",
    "                \"table_to_use\": \"Region\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"region_id\",\n",
    "                    \"column_in_table\" : \"region_code\",\n",
    "                    \"column_in_file\" : \"production_countries\",\n",
    "                    \"column_type\" : list,\n",
    "                    \"type_if_list\": str\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": 'Title_by_production_company',\n",
    "        \"path_file\": '../Data_Files/data/tmdb_full_separator.csv',\n",
    "        \"delimiter\": \"|\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"imdb_id\",\n",
    "                \"column_in_table\": \"title_id\",\n",
    "                \"column_type\": str\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\": [\n",
    "            {   \"column_in_table\": \"production_company_id\",\n",
    "                \"table_to_use\": \"Production_company\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"production_company_id\",\n",
    "                    \"column_in_table\" : \"production_company_name\",\n",
    "                    \"column_in_file\" : \"production_companies_name\",\n",
    "                    \"column_type\" : list,\n",
    "                    \"type_if_list\": str\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": 'Crew',\n",
    "        \"path_file\": '../Data_Files/data/title.crew.tsv',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"tconst\",\n",
    "                \"column_in_table\": \"title_id\",\n",
    "                \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "                \"column_in_file\": \"directors\",\n",
    "                \"column_in_table\": \"person_id\",\n",
    "                \"column_type\": list,\n",
    "                \"type_if_list\": str\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\": [\n",
    "            {   \n",
    "                \"column_in_table\": \"profession_id\",\n",
    "                \"table_to_use\": \"Profession\",\n",
    "                \"default_value\": \"director\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"profession_id\",\n",
    "                    \"column_in_table\" : \"profession_name\",\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": 'Crew',\n",
    "        \"path_file\": '../Data_Files/data/title.crew.tsv',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"tconst\",\n",
    "                \"column_in_table\": \"title_id\",\n",
    "                \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "                \"column_in_file\": \"writers\",\n",
    "                \"column_in_table\": \"person_id\",\n",
    "                \"column_type\": list,\n",
    "                \"type_if_list\": str\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\": [\n",
    "            {   \n",
    "                \"column_in_table\": \"profession_id\",\n",
    "                \"table_to_use\": \"Profession\",\n",
    "                \"default_value\": \"writer\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"profession_id\",\n",
    "                    \"column_in_table\" : \"profession_name\",\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": 'Crew',\n",
    "        \"path_file\": '../Data_Files/data/title.principals.tsv',\n",
    "        \"delimiter\": \"\\t\",\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"tconst\",\n",
    "                \"column_in_table\": \"title_id\",\n",
    "                \"column_type\": str\n",
    "            },\n",
    "            {\n",
    "                \"column_in_file\": \"nconst\",\n",
    "                \"column_in_table\": \"person_id\",\n",
    "                \"column_type\": str,\n",
    "            }\n",
    "        ],\n",
    "        \"referenced_columns\": [\n",
    "            {   \n",
    "                \"column_in_table\": \"profession_id\",\n",
    "                \"table_to_use\": \"Profession\",\n",
    "                \"columns_of_reference\":{\n",
    "                    \"column_id_in_table\" : \"profession_id\",\n",
    "                    \"column_in_table\" : \"profession_name\",\n",
    "                    \"column_in_file\" : \"category\",\n",
    "                    \"column_type\" : str,\n",
    "                }                 \n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe51d8-52e0-4642-ae3d-a54c203da2bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **`table_to_update_info`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b557a0ff-960f-4250-a0e4-6de49f5ff77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of dictionaries\n",
    "tables_to_update_info = [\n",
    "    {\n",
    "        \"table_name\": 'Title',\n",
    "        \"path_file\": '../Data_Files/data/tmdb_full_separator.csv',\n",
    "        \"delimiter\": \"|\",\n",
    "        \"columns_for_condition\":[\n",
    "            {\n",
    "                \"column_in_file\": \"imdb_id\",\n",
    "                \"column_in_table\": \"title_id\",\n",
    "                \"column_type\": str\n",
    "            }\n",
    "        ],\n",
    "        \"columns\":[\n",
    "            {\n",
    "                \"column_in_file\": \"budget\",\n",
    "                \"column_in_table\": \"budget\",\n",
    "                \"column_type\": int\n",
    "            },\n",
    "            {\n",
    "                \"column_in_file\": \"revenue\",\n",
    "                \"column_in_table\": \"revenue\",\n",
    "                \"column_type\": int\n",
    "            },\n",
    "            {\n",
    "                \"column_in_file\": \"overview\",\n",
    "                \"column_in_table\": \"overview\",\n",
    "                \"column_type\": str\n",
    "            }\n",
    "        ]\n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3955cc-8f76-4fec-b7ed-c62cd69aa204",
   "metadata": {},
   "source": [
    "#### **`main` function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0a0cb4-c491-4894-b7ba-27841433f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to orchestrate the entire process\n",
    "def main():\n",
    "    # SQLite connection\n",
    "    sqlite_connection = SQLiteDatabase(sqlite3_db)\n",
    "\n",
    "    # MySQL connection\n",
    "    mysql_connection = MySQLDatabase(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"password\",\n",
    "        database=\"mysql_database\"\n",
    "    )\n",
    "\n",
    "    # Populate the SQLite database and transfer data to MySQL\n",
    "    data_processor = DataProcessor(sqlite_connection, mysql_connection)\n",
    "\n",
    "    # Process and insert data\n",
    "    data_processor.process_flat_tables(flat_tables_info)\n",
    "    data_processor.process_regular_tables(regular_tables_info)\n",
    "    data_processor.process_join_tables(join_tables_info)\n",
    "    data_processor.process_update_tables(tables_to_update_info)\n",
    "\n",
    "    # Close connections\n",
    "    data_processor.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f8e89-ed9e-4a78-826b-83b1ab22a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d480a1-e061-4686-bcec-b109e6672379",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733179fe-4ff1-47f2-88e9-b21c5c8e7d1c",
   "metadata": {},
   "source": [
    "## WEIGHTED_RATING VIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9031353b-e650-494b-b3eb-6bf27d7f7d0c",
   "metadata": {},
   "source": [
    "```sql\n",
    "CREATE VIEW Weighted_rating AS\n",
    "WITH min_votes AS (\n",
    "\tWITH Rating_Full AS (\n",
    "\t\tSelect num_votes, ntile(100) over(order by num_votes ) as percentile \n",
    "\t\tfrom Rating WHERE num_votes IS NOT NULL)\n",
    "\tSELECT MAX(num_votes) AS min_votes FROM Rating_Full WHERE percentile = 95\n",
    "),\n",
    "mean_rating AS (\n",
    "\tSELECT AVG(average_rating) AS mean_rating FROM Rating\n",
    ")\n",
    "SELECT r.rating_id, r.title_id, r.num_votes, r.average_rating, ((r.num_votes*r.average_rating)/ (r.num_votes + m.min_votes) + (m.min_votes*c.mean_rating)/ (r.num_votes + m.min_votes))  AS weighted_rating \n",
    "FROM Rating AS r, min_votes as m, mean_rating as c ORDER BY weighted_rating DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0828c1f-71fa-461c-ae58-954d78c2de18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## KPIs Finances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72fa70-c136-4e46-a1c5-27e0563267c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Rentabilidad Promedio de las Producciones (Revenue / Budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf7648-1606-453f-82d5-5ff443dae908",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT t.primary_title, t.revenue, t.budget, \n",
    "      (t.revenue / t.budget) AS profitability\n",
    "FROM Title t\n",
    "WHERE t.budget > 0;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2b0d8-77cb-40eb-843b-df4de4f0f4b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- __KPI__ : Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40890d78-2bef-4aca-a444-9fb35f31a4ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Revenue moyen par genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e179153-74c5-47e3-95b0-4e389540278c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT g.genre_name, AVG(t.revenue) AS average_revenue\n",
    "FROM Title t\n",
    "JOIN Genres_of_title gt ON t.title_id = gt.title_id\n",
    "JOIN Genre g ON gt.genre_id = g.genre_id\n",
    "GROUP BY g.genre_name;\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af384c1-a63f-4a2c-8898-fbd6a2b09ddb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- __KPI__ : Stack Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733225aa-5ed6-4039-9600-d0baebc47651",
   "metadata": {},
   "source": [
    "### Revenue total par year\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0373c5-cfc2-4c06-a491-4a824e525f73",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT t.start_year, SUM(t.revenue) AS total_revenue\n",
    "FROM Title t\n",
    "GROUP BY t.start_year\n",
    "ORDER BY t.start_year;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1736acb-01fe-41ce-a20b-4d3b52854a25",
   "metadata": {},
   "source": [
    "- __KPI__ : Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae805876-e6dc-4278-b61e-8306557c462c",
   "metadata": {},
   "source": [
    "### Titres avec le plus haut revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d752570-48f9-48f5-9d21-bf9543f901c9",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT t.primary_title, t.revenue\n",
    "FROM Title t\n",
    "ORDER BY t.revenue DESC\n",
    "LIMIT 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae50565-a145-4a53-913e-dd5e2a466dc4",
   "metadata": {},
   "source": [
    "- __KPI__ : Horizontal Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194b963-6719-43d1-aec8-9ba9c75bd07f",
   "metadata": {},
   "source": [
    "### Pourcentage de Titles par range 0 < 1 < 10 < 50 < 100 des revenues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39c9ba-a533-4e4b-8387-af453d07b196",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "  \n",
    "```sql\n",
    "SELECT (COUNT(*) * 100.0) / (SELECT COUNT(*) FROM Title) AS percentage_above_100M\n",
    "FROM Title\n",
    "WHERE revenue > 100000000;\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7a545-696e-45fc-b93f-65a227de3456",
   "metadata": {},
   "source": [
    "- __KPI__ : Pie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b124a8-d6c3-4eea-b046-56844aef1b47",
   "metadata": {},
   "source": [
    "### Rating moyen par Revenue (Rating vs. Revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7f15f-d37c-46ba-ad6e-16dab856035a",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "  \n",
    "```sql\n",
    "SELECT t.primary_title, r.average_rating, t.revenue\n",
    "FROM Title t\n",
    "JOIN Rating r ON t.title_id = r.title_id;\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e1735-745c-4e31-817b-51a39d6cfd9f",
   "metadata": {},
   "source": [
    "- __KPI__ : Scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9fda9-c6e4-42e4-a6f7-d3f1cc12d390",
   "metadata": {},
   "source": [
    "### Total de Títulos por Rango de Ingresos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76afa8f4-82bb-47d3-a70d-9d293f2cb3da",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "   CASE \n",
    "       WHEN t.revenue < 1000000 THEN 'Less than 1M'\n",
    "       WHEN t.revenue BETWEEN 1000000 AND 10000000 THEN '1M - 10M'\n",
    "       WHEN t.revenue BETWEEN 10000000 AND 100000000 THEN '10M - 100M'\n",
    "       ELSE 'More than 100M'\n",
    "   END AS revenue_range,\n",
    "   COUNT(*) AS total_titles\n",
    "FROM Title t\n",
    "GROUP BY revenue_range;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf3d3e-f566-46f9-8f84-eea7eeca177d",
   "metadata": {},
   "source": [
    "- __KPI__ : Stack Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86069a1-09e7-47d1-a6f2-3d61af6b0703",
   "metadata": {},
   "source": [
    "### Títulos con el Mejor Margen de Rentabilidad (Revenue - Budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047bfb96-238e-4594-8b17-ba9ae4029ebb",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT t.primary_title, (t.revenue - t.budget) AS profit_margin\n",
    "FROM Title t\n",
    "WHERE t.budget > 0\n",
    "ORDER BY profit_margin DESC\n",
    "LIMIT 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cc1491-a8d3-46c6-9763-3479501b6340",
   "metadata": {},
   "source": [
    "- __KPI__ : Horizontal bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fb715-074c-42bd-84cf-052c0eb09f1b",
   "metadata": {},
   "source": [
    "### Ingresos por Compañía Productora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d6415-3d9b-4f52-919c-684c550ecdf4",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT pc.production_company_name, SUM(t.revenue) AS total_revenue\n",
    "FROM Production_company pc\n",
    "JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "JOIN Title t ON tpc.title_id = t.title_id\n",
    "GROUP BY pc.production_company_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f492a8a-8045-4bfc-86c5-13fc9633c04b",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5c191-af1c-4849-a779-33cc16f34b9e",
   "metadata": {},
   "source": [
    "### Ingresos Promedio por Género y Año"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aeb22b-0364-46cc-a8e7-e7b827dc836e",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT g.genre_name, t.start_year, AVG(t.revenue) AS avg_revenue\n",
    "FROM Title t\n",
    "JOIN Genres_of_title gt ON t.title_id = gt.title_id\n",
    "JOIN Genre g ON gt.genre_id = g.genre_id\n",
    "GROUP BY g.genre_name, t.start_year\n",
    "ORDER BY t.start_year;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df7f01-d959-4bce-9c99-bf91ea8b68e3",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442b8124-3ff3-44f9-a24b-2243dcdb2290",
   "metadata": {},
   "source": [
    "\n",
    "## KPIs de Recursos Humanos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612143a9-cbbe-4fe5-a76d-fcd9b5b4513d",
   "metadata": {},
   "source": [
    "### Número de Profesionales Involucrados en la Industria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fab7f5-1e0d-405e-85c7-8002d2bb190f",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT COUNT(DISTINCT person_Id) AS total_professionals\n",
    "FROM Crew;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9de06-6773-4d41-b67f-0453fc85a8ec",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f7c94-2ec8-42e9-be57-daf8430bb733",
   "metadata": {},
   "source": [
    "### Profesiones Más Comunes en las Producciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe75887-8b53-48cb-b7c6-5522b52eae70",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT pr.profession_name, COUNT(*) AS count\n",
    "FROM Crew c\n",
    "JOIN Profession pr ON c.profession_id = pr.profession_id\n",
    "GROUP BY pr.profession_name\n",
    "ORDER BY count DESC\n",
    "LIMIT 5;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0209eb6a-fbe9-4eb8-a300-7675ef1ef347",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5dfe64-616f-4622-ab3a-6f7a07ec3ca8",
   "metadata": {},
   "source": [
    "### Promedio de Participación por Persona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b22d7-7014-4a39-815b-2e5d52503e95",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT p.primary_name, COUNT(DISTINCT c.title_id) AS titles_participated\n",
    "FROM Person p\n",
    "JOIN Crew c ON p.person_Id = c.person_Id\n",
    "GROUP BY p.person_Id;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a4071-1d13-40ff-9919-a85e5c4769ad",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1dd5b-5665-4f77-9bab-75c3104bbd64",
   "metadata": {},
   "source": [
    "### Top 3 Profesionales Más Involucrados (Número de Títulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26106ac6-786e-4a00-9386-cda711c83df9",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT p.primary_name, COUNT(DISTINCT c.title_id) AS titles_count\n",
    "FROM Person p\n",
    "JOIN Crew c ON p.person_Id = c.person_Id\n",
    "GROUP BY p.person_Id\n",
    "ORDER BY titles_count DESC\n",
    "LIMIT 3;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6090df-4ebd-49b2-82be-d7ac564b2f98",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def66384-2abc-4155-8a01-4dccb86616a6",
   "metadata": {},
   "source": [
    "### Profesionales más Exitosos por Rating Promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3805c-93f6-48ac-a63a-4dae9ad6a1bb",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT p.primary_name, AVG(r.average_rating) AS avg_rating\n",
    "FROM Person p\n",
    "JOIN Crew c ON p.person_Id = c.person_Id\n",
    "JOIN Title t ON c.title_id = t.title_id\n",
    "JOIN Rating r ON t.title_id = r.title_id\n",
    "GROUP BY p.primary_name\n",
    "ORDER BY avg_rating DESC\n",
    "LIMIT 5;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909285c-d715-4e69-be42-cb8087ebe2fb",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ad598-11dc-4cc1-b56d-d80dc6c0d5fa",
   "metadata": {},
   "source": [
    "### Número de Películas por Profesional y Profesión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194da239-f4bd-4e3a-82f3-6e2b5795b99b",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT p.primary_name, pr.profession_name, COUNT(DISTINCT c.title_id) AS total_titles\n",
    "FROM Person p\n",
    "JOIN Crew c ON p.person_Id = c.person_Id\n",
    "JOIN Profession pr ON c.profession_id = pr.profession_id\n",
    "GROUP BY p.primary_name, pr.profession_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536a383-bc9a-4d08-a228-6ede8f846b89",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96381f9c-40e8-48b2-b313-c08d6ec2c4ba",
   "metadata": {},
   "source": [
    "### Promedio de Participación de Profesionales por Género"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a290683-02ec-4157-b89e-b4a9242f0fae",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT pr.profession_name, g.genre_name, COUNT(DISTINCT c.title_id) / COUNT(DISTINCT p.person_Id) AS avg_participation\n",
    "FROM Crew c\n",
    "JOIN Profession pr ON c.profession_id = pr.profession_id\n",
    "JOIN Person p ON c.person_Id = p.person_Id\n",
    "JOIN Genres_of_title gt ON c.title_id = gt.title_id\n",
    "JOIN Genre g ON gt.genre_id = g.genre_id\n",
    "GROUP BY pr.profession_name, g.genre_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ebe934-8ffe-4d1e-8290-a0a277e5141d",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5ef37-15fb-4ee9-a7e5-0d3bf7affe7b",
   "metadata": {},
   "source": [
    "### Número de Profesionales por Región"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bc8be-d2e2-4795-a7cc-418ccdbd7ffb",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT r.region_name, COUNT(DISTINCT c.person_Id) AS total_professionals\n",
    "FROM Region r\n",
    "JOIN Production_company pc ON r.region_id = pc.region_id\n",
    "JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "JOIN Crew c ON tpc.title_id = c.title_id\n",
    "GROUP BY r.region_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a53ce-9c38-4821-a026-d63e32af5033",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1201a64-3ede-44f6-9a6d-a578926ddcaf",
   "metadata": {},
   "source": [
    "### Profesionales por Título (Promedio de Profesionales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997257f-130f-461e-9389-ef1cb871e7a5",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT t.primary_title, COUNT(DISTINCT c.person_Id) AS professionals_count\n",
    "FROM Title t\n",
    "JOIN Crew c ON t.title_id = c.title_id\n",
    "GROUP BY t.title_id;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcd2990-ef00-44a6-9641-e8f83e268b60",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50291ac9-250d-4dce-bc13-f0278af9f0ef",
   "metadata": {},
   "source": [
    "### Número de Profesionales por Año de Producción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13d590-60c2-489a-90c2-3283e6d6b7b8",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT t.start_year, COUNT(DISTINCT c.person_Id) AS total_professionals\n",
    "FROM Title t\n",
    "JOIN Crew c ON t.title_id = c.title_id\n",
    "GROUP BY t.start_year;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb9ae50-b993-4df4-89ce-8c80171e229e",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ac574-717e-4d88-b4d0-62198a164906",
   "metadata": {},
   "source": [
    "## KPIs de Países y Lenguajes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e670a-ae57-41bc-876a-8b98e3f611a7",
   "metadata": {},
   "source": [
    "### Número de Títulos por Región"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62868595-4606-4320-80f2-cb76814c9fe7",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT r.region_name, COUNT(DISTINCT t.title_id) AS titles_count\n",
    "FROM Region r\n",
    "JOIN Title_production_region tpr ON r.region_id = tpr.region_id\n",
    "JOIN Title t ON tpr.title_id = t.title_id\n",
    "GROUP BY r.region_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f105c-2236-4761-a4ec-ad10531e9ad5",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7694e3-241b-4693-b799-a4a0e85936c2",
   "metadata": {},
   "source": [
    "### Distribución de Idiomas por Título"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83b63e-2e36-4ea1-94e4-95b5912dbdea",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT t.primary_title, COUNT(DISTINCT sl.language_id) AS languages_count\n",
    "FROM Title t\n",
    "JOIN Spoken_languages_in_title sl ON t.title_id = sl.title_id\n",
    "GROUP BY t.title_id;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48607097-8544-4542-a6e3-d65e57e69166",
   "metadata": {},
   "source": [
    "- __KPI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2fc84-a774-4259-bfe5-1612d9103bb4",
   "metadata": {},
   "source": [
    "### Porcentaje de Títulos con Múltiples Idiomas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9dfd5e-52c1-4390-8cd1-c5f8223bb929",
   "metadata": {},
   "source": [
    "- __SQL__\n",
    "\n",
    "```sql\n",
    "SELECT (COUNT(DISTINCT t.title_id) * 100.0) / (SELECT COUNT(*) FROM Title) AS percentage_multi_language\n",
    "FROM Title t\n",
    "JOIN Spoken_languages_in_title sl ON t.title_id = sl.title_id\n",
    "GROUP BY t.title_id\n",
    "HAVING COUNT(DISTINCT sl.language_id) > 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f85dba-a272-43c5-abbb-8fae02c83a1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8213c53-bd0c-4309-aca6-727b09ab562f",
   "metadata": {},
   "source": [
    "### 4. Promedio de Títulos por Región\n",
    "   SELECT AVG(title_count) AS avg_titles_per_region\n",
    "   FROM (SELECT r.region_name, COUNT(DISTINCT t.title_id) AS title_count\n",
    "         FROM Region r\n",
    "         JOIN Title_production_region tpr ON r.region_id = tpr.region_id\n",
    "         JOIN Title t ON tpr.title_id = t.title_id\n",
    "         GROUP BY r.region_name) AS region_titles;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f83a2f1-5971-494f-95c3-5d066057450c",
   "metadata": {},
   "source": [
    "### 5. Número de Idiomas por Región\n",
    "   SELECT r.region_name, COUNT(DISTINCT sl.language_id) AS languages_count\n",
    "   FROM Region r\n",
    "   JOIN Title_production_region tpr ON r.region_id = tpr.region_id\n",
    "   JOIN Title t ON tpr.title_id = t.title_id\n",
    "   JOIN Spoken_languages_in_title sl ON t.title_id = sl.title_id\n",
    "   GROUP BY r.region_name;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2da09-9313-46c4-8607-acf6ec4d26fc",
   "metadata": {},
   "source": [
    "### 6. Top 5 Idiomas Más Comunes\n",
    "   SELECT l.language_name, COUNT(*) AS language_count\n",
    "   FROM Spoken_languages_in_title sl\n",
    "   JOIN Language l ON sl.language_id = l.language_id\n",
    "   GROUP BY l.language_name\n",
    "   ORDER BY language_count DESC\n",
    "   LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42054f6a-2f1b-4922-ad97-21f9afa52d2d",
   "metadata": {},
   "source": [
    "### 7. Títulos Doblados vs. Subtitulados\n",
    "   SELECT \n",
    "       CASE\n",
    "           WHEN rt.is_original_title = 1 THEN 'Original'\n",
    "           ELSE 'Doblado/Subtitulado'\n",
    "       END AS title_type,\n",
    "       COUNT(DISTINCT t.title_id) AS titles_count\n",
    "   FROM Regional_Title rt\n",
    "   JOIN Title t ON rt.title_id = t.title_id\n",
    "   GROUP BY title_type;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bbc1a5-5191-460b-820d-91c2a891d077",
   "metadata": {},
   "source": [
    "### 8. Títulos por Región y Idioma\n",
    "   SELECT r.region_name, l.language_name, COUNT(DISTINCT t.title_id) AS titles_count\n",
    "   FROM Region r\n",
    "   JOIN Title_production_region tpr ON r.region_id = tpr.region_id\n",
    "   JOIN Title t ON tpr.title_id = t.title_id\n",
    "   JOIN Spoken_languages_in_title sl ON t.title_id = sl.title_id\n",
    "   JOIN Language l ON sl.language_id = l.language_id\n",
    "   GROUP BY r.region_name, l.language_name;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d2346-ecfe-46de-a306-daf314f0ed2a",
   "metadata": {},
   "source": [
    "### 9. Títulos en Idiomas No Nativos (Por Región)\n",
    "   SELECT r.region_name, COUNT(DISTINCT t.title_id) AS non_native_titles\n",
    "   FROM Region r\n",
    "   JOIN Title_production_region tpr ON r.region_id = tpr.region_id\n",
    "   JOIN Title t ON tpr.title_id = t.title_id\n",
    "   JOIN Regional_Title rt ON t.title_id = rt.title_id\n",
    "   WHERE rt.is_original_title = 0\n",
    "   GROUP BY r.region_name;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1298d-6cb5-4db3-8f0d-cff85a39c28a",
   "metadata": {},
   "source": [
    "### 10. Número de Idiomas en los Títulos por Año\n",
    "    SELECT t.start_year, COUNT(DISTINCT sl.language_id) AS languages_count\n",
    "    FROM Title t\n",
    "    JOIN Spoken_languages_in_title sl ON t.title_id = sl.title_id\n",
    "    GROUP BY t.start_year;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdd404-36bf-484b-a54e-883457312467",
   "metadata": {},
   "source": [
    "## KPIs de Compañías Productoras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44c089-e08c-4807-9665-bcd3fc3e7400",
   "metadata": {},
   "source": [
    "### 1. Total de Ingresos por Compañía Productora\n",
    "   SELECT pc.production_company_name, SUM(t.revenue) AS total_revenue\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   GROUP BY pc.production_company_name;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bffaf6-36dd-4f26-b86e-1e9bb895bbc4",
   "metadata": {},
   "source": [
    "### 2. Número de Títulos por Compañía Productora\n",
    "   SELECT pc.production_company_name, COUNT(*) AS total_titles\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   GROUP BY pc.production_company_name;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa9185-acd0-4885-96a8-7b123d2d0c0f",
   "metadata": {},
   "source": [
    "### 3. Top 10 Compañías Productoras con Mayor Ingreso\n",
    "   SELECT pc.production_company_name, SUM(t.revenue) AS total_revenue\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   GROUP BY pc.production_company_name\n",
    "   ORDER BY total_revenue DESC\n",
    "   LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8f0e5-5d8d-4a63-a7f4-f470c6cba49e",
   "metadata": {},
   "source": [
    "### 4. Compañías Productoras con Más Títulos\n",
    "   SELECT pc.production_company_name, COUNT(*) AS total_titles\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   GROUP BY pc.production_company_name\n",
    "   ORDER BY total_titles DESC\n",
    "   LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225551aa-a09f-4634-9bd4-b2dfa92972b8",
   "metadata": {},
   "source": [
    "### 5. Promedio de Ingresos por Título por Compañía Productora\n",
    "   SELECT pc.production_company_name, AVG(t.revenue) AS avg_revenue_per_title\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   GROUP BY pc.production_company_name;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93afb58-d061-4d24-8c24-92c8d3210ce6",
   "metadata": {},
   "source": [
    "### 6. Total de Ingresos por Compañía Productora y Año\n",
    "   SELECT pc.production_company_name, t.start_year, SUM(t.revenue) AS total_revenue\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   GROUP BY pc.production_company_name, t.start_year\n",
    "   ORDER BY t.start_year;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b370b0-c68b-4e2f-ae8f-4a5a600ae74c",
   "metadata": {},
   "source": [
    "### 7. Top 5 Compañías Productoras por Rating Promedio\n",
    "   SELECT pc.production_company_name, AVG(r.average_rating) AS avg_rating\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   JOIN Rating r ON t.title_id = r.title_id\n",
    "   GROUP BY pc.production_company_name\n",
    "   ORDER BY avg_rating DESC\n",
    "   LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0d6be-d555-45d2-8d99-e5386d5bbb1e",
   "metadata": {},
   "source": [
    "### 8. Ingresos por Compañía Productora en los Últimos 5 Años\n",
    "   SELECT pc.production_company_name, SUM(t.revenue) AS total_revenue\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   WHERE t.start_year >= (YEAR(CURDATE()) - 5)\n",
    "   GROUP BY pc.production_company_name;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a286f66-abfe-498a-bed8-d62a1d15d147",
   "metadata": {},
   "source": [
    "### 9. Promedio de Títulos por Compañía Productora por Año\n",
    "   SELECT pc.production_company_name, t.start_year, COUNT(*) / COUNT(DISTINCT t.start_year) AS avg_titles_per_year\n",
    "   FROM Production_company pc\n",
    "   JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "   JOIN Title t ON tpc.title_id = t.title_id\n",
    "   GROUP BY pc.production_company_name, t.start_year;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131607d4-1350-43d7-986c-fc14a41642fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 10. Compañías Productoras y sus Títulos Más Rentables\n",
    "    SELECT pc.production_company_name, t.primary_title, t.revenue\n",
    "    FROM Production_company pc\n",
    "    JOIN Title_by_production_company tpc ON pc.production_company_id = tpc.production_company_id\n",
    "    JOIN Title t ON tpc.title_id = t.title_id\n",
    "    ORDER BY t.revenue DESC\n",
    "    LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a60eb3-2f67-46ed-8340-e036bff4a804",
   "metadata": {},
   "source": [
    "# __SYSTEM RECOMMENDATION ENGINE__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5557f-6066-4b77-b387-349ccddd942c",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0861a0-8571-4ac0-9af0-01c74503d0a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __Python imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50779725-ee48-4d40-a54b-4eeb47455a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a2bfa-fcb4-4e15-89df-4bdb0f1a3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb = pd.read_csv(filepath_or_buffer=\"../Data_Files/data/TMDB_movie_dataset_v11.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7404c4-2f16-41cb-a033-8c5d8bbb0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = pd.read_csv(filepath_or_buffer=\"../Data_Files/data/title.crew.tsv.gz\",compression=\"gzip\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4526a-601d-4aa2-a6d6-804224e2a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.read_csv(filepath_or_buffer=\"../Data_Files/data/name.basics.tsv.gz\",compression=\"gzip\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ade90e-1a6e-428c-adf2-e84e6c167ec7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __UTILS FUNCTIONS__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbede6-5cca-4807-a4d2-cba7dc41bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_na_by_columns(dataframe: pd.DataFrame):\n",
    "    flag = True\n",
    "    for column in dataframe.columns:\n",
    "        count = dataframe[column].isna().sum()\n",
    "        if count > 0:\n",
    "            flag = False\n",
    "            print(f\"The column {column} has {count} null cells \")\n",
    "    if flag:\n",
    "        print(f\"There aren't null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906487b-ea38-4455-84aa-853b7e9bc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basic_analysis(dataframe: pd.DataFrame, dataframe_name: str = 'DATAFRAME'):\n",
    "    print(f\"-------------------------------------------------------------------------------------\")\n",
    "    print(f\"------------------------------{dataframe_name}---------------------------------------\")\n",
    "    print(dataframe.head(5), end=\"\\n\\n\")\n",
    "    print(dataframe.info(), end=\"\\n\\n\")\n",
    "    print_na_by_columns(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569badf-c99b-476b-9f60-ca854b3598c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates_by_column(dataframe: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    for column in columns:\n",
    "        dataframe = dataframe.loc[~dataframe.duplicated(subset=column)]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2628e12-c0e8-44a4-9ad6-e52b84ca85cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __INITIAL ANALYSIS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d19110-f704-4308-a576-8176a226ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_basic_analysis(tmdb, 'TMDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324578eb-71e3-49f9-b66c-6c70dc26f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_basic_analysis(crew, 'CREW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080eb4e-4922-4c2e-ac5a-11a85fcd423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_basic_analysis(people, 'PEOPLE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6911e9-eece-4c05-ae69-571ae8e5eb83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __ONLY NECESSARY COLUMNS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a18bc8-0b0e-4315-b105-57a31ccca098",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_columns = ['id', 'title', 'vote_average', 'vote_count', 'release_date', 'poster_path',\n",
    "       'imdb_id', 'original_title', 'overview',\n",
    "       'popularity', 'tagline', 'genres','keywords']\n",
    "tmdb = tmdb[tmdb_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a3549-07e5-462d-8620-5b5198580706",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_columns = ['tconst', 'directors']\n",
    "crew = crew[crew_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af7e26-c78f-4905-a3a8-23333da4ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_columns = ['nconst', 'primaryName']\n",
    "people = people[people_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d3f35-d8d0-43ac-a966-a97fafe54431",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __REMOVE ROWS WITH NULL VALUES__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9ee46-a63b-463c-8b6c-6ed9446729c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colums_not_na = ['id', 'title', 'vote_average', 'vote_count',\n",
    "       'imdb_id', 'original_title', 'overview',\n",
    "       'popularity', 'genres']\n",
    "tmdb.dropna(subset=colums_not_na, inplace=True, axis=0)\n",
    "\n",
    "print(tmdb.info(), end=\"\\n\\n\")\n",
    "print_na_by_columns(tmdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e81c67-2480-4002-b9c4-634c2c3c70e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "people.dropna(inplace=True, axis=0)\n",
    "\n",
    "print(people.info(), end=\"\\n\\n\")\n",
    "print_na_by_columns(people)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4640626-1eb5-42d3-a462-06e923e1db9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __REMOVING DUPLICATES COLUMS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aee149-154f-442c-bb80-fc077c7d0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"TMDB size before: {len(tmdb)}\")\n",
    "tmdb = remove_duplicates_by_column(tmdb, ['id', 'imdb_id'])\n",
    "print(f\"TMDB size after: {len(tmdb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de452484-fefd-4644-88e0-f939d71c4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PEOPLE size before: {len(people)}\")\n",
    "people = remove_duplicates_by_column(people, ['nconst'])\n",
    "print(f\"PEOPLE size after: {len(people)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758f140-b7f9-4fdf-8e25-a1d163f1b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CREW size before: {len(crew)}\")\n",
    "crew = remove_duplicates_by_column(crew, ['tconst'])\n",
    "print(f\"CREW size after: {len(crew)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2136602f-a769-4180-818c-901d4336626b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __JOIN DATAFRAMES__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b7e1e-6711-4fd5-ba06-3ad15e4df05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb = pd.merge(tmdb, crew, how='left', left_on='imdb_id', right_on='tconst').drop(columns=['imdb_id', 'tconst'])\n",
    "tmdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ea5c5-8665-41f1-89b1-752ffe42f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "people.set_index('nconst', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f21656-cace-41f1-a752-8e2a979b49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_name(nconst:str):\n",
    "    primary_name = people.loc[nconst, 'primaryName']\n",
    "    return primary_name if primary_name != '' else None\n",
    "\n",
    "def get_primary_names(nconsts: str) -> str:\n",
    "    names_list = [get_primary_name(str(nconst).strip()) for nconst in nconsts.split(',') if nconst.strip() not in ['\\\\N', '']]\n",
    "    return ','.join(names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d14c2a-87f5-47a1-aff6-b1915c706f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.fillna({'directors':''}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8462bd9-ef9c-43de-bdfa-39cebb3146f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb['directors'] = tmdb['directors'].apply(get_primary_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522589bb-bde2-4778-873e-f9fd458636ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.fillna({'genres':''}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127e932-7497-4356-8093-bd797c64a2e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __SAVE DATAFRAME TO CSV FILE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f934e8e-3700-4b94-9e77-d2a1fffca68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.to_csv(path_or_buf=\"../Data_Files/data/TMDB_movies_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a813a5-f07d-406f-a2df-2b51ccef205e",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fa80b-81c0-41be-a633-07470c019db2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __Python imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde8673e-1959-4228-84fd-565c628ed072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import hstack\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579572b7-043e-49df-b52c-680125eba615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gabriel-\n",
      "[nltk_data]     santisteban/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504ed5a-1193-44e6-8807-446cbaa0d2ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __Utils Functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25efcfb1-34a8-4630-90dd-f499417861fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text: str) -> str:\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r'[^a-z\\s]',\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ce1189-a2f6-4397-bb20-5a1521c9aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_clean_str(x: str, delimiter=\",\", remove_spaces: bool=False):\n",
    "    new_list = []\n",
    "    if isinstance(x, str) and x != None and len(x.strip()) > 0 and x !='\\\\N' and x != np.nan:\n",
    "        new_list = [clean_str(val) for val in x.split(delimiter) if val.strip() != \"\"]\n",
    "    if isinstance(x, list):\n",
    "        new_list = [clean_str(val) for val in x if val and val.strip() != \"\"]\n",
    "    if remove_spaces:\n",
    "        new_list = [val.replace(\" \", \"\") for val in new_list]\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e2912f-f71d-46fc-a625-cb8e5816de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keywords(keywords: list, interesting_keywords: list):\n",
    "    words = []\n",
    "    for word in keywords:\n",
    "        if word in interesting_keywords:\n",
    "            words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb0a75f-30f7-4c98-a841-5b89c6f279ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+').tokenize\n",
    "def split_with_tokenizer(text: str) -> list:\n",
    "    if isinstance(text, str):\n",
    "        return tokenizer(text)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80253fd0-5c8b-4b8e-8a58-22aca643f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lists_to_str(word_lists: list, weight) -> str:\n",
    "    return \" \".join([word for word_list in word_lists  \n",
    "              for word in word_list*weight if word not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432d2a1-42c4-479b-8163-645d9ed1a554",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __Loading Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b2d386b-e574-4e95-89fa-8f560da89a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full = pd.read_csv(filepath_or_buffer=\"../data/TMDB_movies_full.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06bec903-e1ef-4749-8ef2-2dfb28267376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>directors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>Inception</td>\n",
       "      <td>Cobb, a skilled thief who commits corporate es...</td>\n",
       "      <td>83.952</td>\n",
       "      <td>Your mind is the scene of the crime.</td>\n",
       "      <td>Action, Science Fiction, Adventure</td>\n",
       "      <td>rescue, mission, dream, airplane, paris, franc...</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157336</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>32571</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>The adventures of a group of explorers who mak...</td>\n",
       "      <td>140.241</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "      <td>Adventure, Drama, Science Fiction</td>\n",
       "      <td>rescue, future, spacecraft, race against time,...</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.512</td>\n",
       "      <td>30619</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Batman raises the stakes in his war on crime. ...</td>\n",
       "      <td>130.643</td>\n",
       "      <td>Welcome to a world without rules.</td>\n",
       "      <td>Drama, Action, Crime, Thriller</td>\n",
       "      <td>joker, sadism, chaos, secret identity, crime f...</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.573</td>\n",
       "      <td>29815</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>79.932</td>\n",
       "      <td>Enter the world of Pandora.</td>\n",
       "      <td>Action, Adventure, Fantasy, Science Fiction</td>\n",
       "      <td>future, society, culture clash, space travel, ...</td>\n",
       "      <td>James Cameron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24428</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.710</td>\n",
       "      <td>29166</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>When an unexpected enemy emerges and threatens...</td>\n",
       "      <td>98.082</td>\n",
       "      <td>Some assembly required.</td>\n",
       "      <td>Science Fiction, Action, Adventure</td>\n",
       "      <td>new york city, superhero, shield, based on com...</td>\n",
       "      <td>Joss Whedon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id            title  vote_average  vote_count   original_title  \\\n",
       "0   27205        Inception         8.364       34495        Inception   \n",
       "1  157336     Interstellar         8.417       32571     Interstellar   \n",
       "2     155  The Dark Knight         8.512       30619  The Dark Knight   \n",
       "3   19995           Avatar         7.573       29815           Avatar   \n",
       "4   24428     The Avengers         7.710       29166     The Avengers   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  Cobb, a skilled thief who commits corporate es...      83.952   \n",
       "1  The adventures of a group of explorers who mak...     140.241   \n",
       "2  Batman raises the stakes in his war on crime. ...     130.643   \n",
       "3  In the 22nd century, a paraplegic Marine is di...      79.932   \n",
       "4  When an unexpected enemy emerges and threatens...      98.082   \n",
       "\n",
       "                                             tagline  \\\n",
       "0               Your mind is the scene of the crime.   \n",
       "1  Mankind was born on Earth. It was never meant ...   \n",
       "2                  Welcome to a world without rules.   \n",
       "3                        Enter the world of Pandora.   \n",
       "4                            Some assembly required.   \n",
       "\n",
       "                                        genres  \\\n",
       "0           Action, Science Fiction, Adventure   \n",
       "1            Adventure, Drama, Science Fiction   \n",
       "2               Drama, Action, Crime, Thriller   \n",
       "3  Action, Adventure, Fantasy, Science Fiction   \n",
       "4           Science Fiction, Action, Adventure   \n",
       "\n",
       "                                            keywords          directors  \n",
       "0  rescue, mission, dream, airplane, paris, franc...  Christopher Nolan  \n",
       "1  rescue, future, spacecraft, race against time,...  Christopher Nolan  \n",
       "2  joker, sadism, chaos, secret identity, crime f...  Christopher Nolan  \n",
       "3  future, society, culture clash, space travel, ...      James Cameron  \n",
       "4  new york city, superhero, shield, based on com...        Joss Whedon  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e41c3bb-d797-4839-9108-14d95107b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404014 entries, 0 to 404013\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              404014 non-null  int64  \n",
      " 1   title           404014 non-null  object \n",
      " 2   vote_average    404014 non-null  float64\n",
      " 3   vote_count      404014 non-null  int64  \n",
      " 4   original_title  404014 non-null  object \n",
      " 5   overview        404014 non-null  object \n",
      " 6   popularity      404014 non-null  float64\n",
      " 7   tagline         94612 non-null   object \n",
      " 8   genres          404014 non-null  object \n",
      " 9   keywords        178158 non-null  object \n",
      " 10  directors       390423 non-null  object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 33.9+ MB\n"
     ]
    }
   ],
   "source": [
    "tmdb_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3f19b-e794-44a8-82ad-99744979fb94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __Transforming columns__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71018bca-706f-4d82-bfb8-94e9af17bca1",
   "metadata": {},
   "source": [
    "#### __From str to list__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7024294-992c-4b6c-8a84-d95771e5b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full.fillna({'directors':'', 'genres':'', 'keywords':'', 'tagline': '', 'overview':''}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16722051-a23d-45a2-87e4-4652f61d2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['directors'] = tmdb_full['directors'].apply(lambda x: split_and_clean_str(x, remove_spaces=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5080c4f-11fd-415a-8a41-b050c6c23962",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['genres'] = tmdb_full['genres'].apply(lambda x: split_and_clean_str(x, remove_spaces=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eb7739d-fada-4816-a0ce-a851d3ab20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['keywords'] = tmdb_full['keywords'].apply(split_and_clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e180ace-9421-4570-9f12-740ccad1deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['overview'] = tmdb_full['overview'].apply(split_with_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52f65b9c-68f9-4e26-b6cf-94ab602650a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['tagline'] = tmdb_full['tagline'].apply(split_with_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f750abc-88e0-4de3-8ad2-7aa0df50fcaa",
   "metadata": {},
   "source": [
    "#### __Removing `keywords` not interesting -> `keyword occurrences = 1`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9e71683-eddd-42ba-8f53-7f1b295aff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = tmdb_full['keywords'].explode().to_list()\n",
    "all_keywords = sorted([key for key, value in nltk.FreqDist(all_keywords).items() if value > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f69d819-07c7-4c57-b185-dc5227f8bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['keywords'] = tmdb_full['keywords'].apply(lambda x: filter_keywords(x, all_keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e643b87-4539-49e7-ae47-cf31309a0eec",
   "metadata": {},
   "source": [
    "#### __Steaming on `keywords`, `description` and `tagline` and remove spaces between words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92dbdeed-0022-47d8-90f9-d17193cbb770",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72acdfee-75c9-4f33-bb72-4818e1634ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['keywords'] = tmdb_full['keywords'].apply(lambda x: [stemmer.stem(i).replace(\" \", \"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86dc1eb6-035a-40f0-9dd4-09d7c7762834",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['tagline'] = tmdb_full['tagline'].apply(lambda x: [stemmer.stem(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df8da7d9-1a36-4909-a4c0-3e83c5256321",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full['overview'] = tmdb_full['overview'].apply(lambda x: [stemmer.stem(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b2708b-7a91-467c-a468-120042fefcac",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c957e7-a900-427a-ab3e-0c60d93f86d7",
   "metadata": {},
   "source": [
    "### __Vectorizing the text__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e23c2-0016-4c06-8ef7-b974671f7ffb",
   "metadata": {},
   "source": [
    "#### __Using `CountVector` on columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2534ff11-ca89-4c12-8c37-0d73f75efb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_weight = {'overview':1, 'directors':3, 'tagline':1, 'keywords':1, 'genres':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63447e9a-eecc-4edb-b1a0-1084a604dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {col:(CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0.0, stop_words='english'), weight) \n",
    "               for col,weight in columns_weight.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56f8c108-b0ba-475a-bcb1-dbfabbe50934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overview': (CountVectorizer(min_df=0.0, ngram_range=(1, 2), stop_words='english'), 1), 'directors': (CountVectorizer(min_df=0.0, ngram_range=(1, 2), stop_words='english'), 3), 'tagline': (CountVectorizer(min_df=0.0, ngram_range=(1, 2), stop_words='english'), 1), 'keywords': (CountVectorizer(min_df=0.0, ngram_range=(1, 2), stop_words='english'), 1), 'genres': (CountVectorizer(min_df=0.0, ngram_range=(1, 2), stop_words='english'), 2)}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d777e8ed-fc70-4dcb-97b5-cba1ff3ec8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix = []\n",
    "for col, (vect, weight) in vectorizers.items():\n",
    "    all_matrix.append(vect.fit_transform(tmdb_full[col].apply(lambda x: \" \".join(x*weight))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9f0f6-ef23-4178-96ea-787239c42453",
   "metadata": {},
   "source": [
    "#### __Stacking the matrices__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5a0d0e8-7dfd-43de-bf60-6e9066352e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrices = hstack(all_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e93677-02a7-4ef6-84d5-e23a7397df4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __KNN : Creating the Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cb986c5-8643-4c56-8dea-14c665dc42c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKNN = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "modelKNN.fit(all_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b51fe014-5f24-4c8c-ac6b-d67573e451cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = modelKNN.kneighbors(all_matrices[0], n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1290d606-5b7a-49d8-a2cf-614fd60e9993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>directors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>Inception</td>\n",
       "      <td>[cobb, a, skill, thief, who, commit, corpor, e...</td>\n",
       "      <td>83.952</td>\n",
       "      <td>[your, mind, is, the, scene, of, the, crime]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[rescu, mission, dream, airplan, pari, franc, ...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333127</th>\n",
       "      <td>83533</td>\n",
       "      <td>Avatar 3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Avatar 3</td>\n",
       "      <td>[the, third, entri, in, the, avatar, franchis]</td>\n",
       "      <td>14.635</td>\n",
       "      <td>[]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[sequel]</td>\n",
       "      <td>[jamescameron]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19208</th>\n",
       "      <td>10921</td>\n",
       "      <td>Babylon 5: The River of Souls</td>\n",
       "      <td>6.374</td>\n",
       "      <td>91</td>\n",
       "      <td>Babylon 5: The River of Souls</td>\n",
       "      <td>[a, group, of, soul, hunter, come, to, babylon...</td>\n",
       "      <td>8.387</td>\n",
       "      <td>[]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[alienlifeform, womandirector, spacecentr]</td>\n",
       "      <td>[janetgreek]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195890</th>\n",
       "      <td>750535</td>\n",
       "      <td>Monochrome: The Chromism</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>Monochrome: The Chromism</td>\n",
       "      <td>[trade, and, sold, like, currenc, the, outcast...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>[]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kodizene]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321463</th>\n",
       "      <td>278238</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>[the, western, frontier, reemerg, and, as, in,...</td>\n",
       "      <td>2.459</td>\n",
       "      <td>[when, vengeanc, becom, justic]</td>\n",
       "      <td>[adventure, action, sciencefiction]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[jonscuarn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160014</th>\n",
       "      <td>651692</td>\n",
       "      <td>Virtual Death Match</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2</td>\n",
       "      <td>Virtual Death Match</td>\n",
       "      <td>[a, group, of, gamer, are, select, to, take, p...</td>\n",
       "      <td>3.470</td>\n",
       "      <td>[]</td>\n",
       "      <td>[horror, action, sciencefiction, adventure]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[louisawarren]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18345</th>\n",
       "      <td>10916</td>\n",
       "      <td>Babylon 5: A Call to Arms</td>\n",
       "      <td>6.816</td>\n",
       "      <td>98</td>\n",
       "      <td>Babylon 5: A Call to Arms</td>\n",
       "      <td>[alli, of, the, shadow, seek, reveng, against,...</td>\n",
       "      <td>8.286</td>\n",
       "      <td>[]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[spacemarin, nightmar, spacewar, alienlifeform...</td>\n",
       "      <td>[michaelvejar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364</th>\n",
       "      <td>240483</td>\n",
       "      <td>Robot Overlords</td>\n",
       "      <td>4.900</td>\n",
       "      <td>241</td>\n",
       "      <td>Robot Overlords</td>\n",
       "      <td>[earth, has, been, conquer, by, robot, from, a...</td>\n",
       "      <td>12.406</td>\n",
       "      <td>[mankind, may, fall, hero, will, rise]</td>\n",
       "      <td>[sciencefiction, adventure, action]</td>\n",
       "      <td>[invas, robot]</td>\n",
       "      <td>[jonwright]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401778</th>\n",
       "      <td>760328</td>\n",
       "      <td>Robopocalypse</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Robopocalypse</td>\n",
       "      <td>[in, a, futurist, world, a, human, resist, mov...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sciencefiction, adventure, action]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[michaelbay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61976</th>\n",
       "      <td>74839</td>\n",
       "      <td>Star Odyssey</td>\n",
       "      <td>2.200</td>\n",
       "      <td>14</td>\n",
       "      <td>Sette uomini d'oro nello spazio</td>\n",
       "      <td>[earth, is, attack, by, an, intergalact, villa...</td>\n",
       "      <td>2.542</td>\n",
       "      <td>[the, earth, s, ultim, disast]</td>\n",
       "      <td>[sciencefiction, adventure, action]</td>\n",
       "      <td>[alien, robot, spaceopera, outerspac]</td>\n",
       "      <td>[alfonsobrescia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239740</th>\n",
       "      <td>1170847</td>\n",
       "      <td>Star Wars: Revelations</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Star Wars: Revelations</td>\n",
       "      <td>[the, last, jedi, fight, to, surviv, when, the...</td>\n",
       "      <td>0.627</td>\n",
       "      <td>[the, rebellion, begin]</td>\n",
       "      <td>[sciencefiction, adventure, action]</td>\n",
       "      <td>[fanfilm]</td>\n",
       "      <td>[shanefelux]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174104</th>\n",
       "      <td>1004932</td>\n",
       "      <td>The Village</td>\n",
       "      <td>9.000</td>\n",
       "      <td>2</td>\n",
       "      <td>The Village</td>\n",
       "      <td>[in, a, dystopian, world, where, ai, alreadi, ...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sciencefiction, adventure, action]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[shahriargalib]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8631</th>\n",
       "      <td>456048</td>\n",
       "      <td>The Humanity Bureau</td>\n",
       "      <td>4.823</td>\n",
       "      <td>319</td>\n",
       "      <td>The Humanity Bureau</td>\n",
       "      <td>[in, 2030, the, world, is, in, a, perman, stat...</td>\n",
       "      <td>9.816</td>\n",
       "      <td>[in, the, near, futur, our, govern, will, deci...</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[dystopia]</td>\n",
       "      <td>[robwking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175613</th>\n",
       "      <td>270750</td>\n",
       "      <td>NOVR</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2</td>\n",
       "      <td>NOVR</td>\n",
       "      <td>[as, their, planet, is, be, rip, apart, two, y...</td>\n",
       "      <td>0.617</td>\n",
       "      <td>[]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[geofforourke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>72545</td>\n",
       "      <td>Journey 2: The Mysterious Island</td>\n",
       "      <td>6.145</td>\n",
       "      <td>3942</td>\n",
       "      <td>Journey 2: The Mysterious Island</td>\n",
       "      <td>[sean, anderson, partner, with, his, mom, s, b...</td>\n",
       "      <td>42.913</td>\n",
       "      <td>[believ, the, imposs, discov, the, incred]</td>\n",
       "      <td>[adventure, action, sciencefiction]</td>\n",
       "      <td>[mission, giantlizard, missingperson, duringcr...</td>\n",
       "      <td>[bradpeyton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287112</th>\n",
       "      <td>1245917</td>\n",
       "      <td>Crimson Star</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Crimson Star</td>\n",
       "      <td>[plot, under, wrap]</td>\n",
       "      <td>0.750</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sciencefiction, action]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200931</th>\n",
       "      <td>536422</td>\n",
       "      <td>Steamwrecked</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1</td>\n",
       "      <td>Steamwrecked</td>\n",
       "      <td>[after, their, lightn, catch, zeppelin, crash,...</td>\n",
       "      <td>0.683</td>\n",
       "      <td>[]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[zeppelin, steampunk, desert, steampow, shortf...</td>\n",
       "      <td>[christophermatista]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>118340</td>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>7.906</td>\n",
       "      <td>26638</td>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>[light, year, from, earth, 26, year, after, be...</td>\n",
       "      <td>33.255</td>\n",
       "      <td>[all, hero, start, somewher]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[spacecraft, basedoncom, space, orphan, advent...</td>\n",
       "      <td>[jamesgunn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25858</th>\n",
       "      <td>443297</td>\n",
       "      <td>Moontrap: Target Earth</td>\n",
       "      <td>4.527</td>\n",
       "      <td>56</td>\n",
       "      <td>Moontrap: Target Earth</td>\n",
       "      <td>[a, long, forgotten, ancient, spacecraft, disc...</td>\n",
       "      <td>10.762</td>\n",
       "      <td>[]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[robertdyke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>426285</td>\n",
       "      <td>Fullmetal Alchemist</td>\n",
       "      <td>5.401</td>\n",
       "      <td>507</td>\n",
       "      <td>鋼の錬金術師</td>\n",
       "      <td>[two, alchemist, brother, go, on, a, quest, fo...</td>\n",
       "      <td>12.863</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fantasy, action, sciencefiction, adventure]</td>\n",
       "      <td>[basedonmanga, alchemi]</td>\n",
       "      <td>[fumihikosori]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                             title  vote_average  vote_count  \\\n",
       "0         27205                         Inception         8.364       34495   \n",
       "333127    83533                          Avatar 3         0.000           0   \n",
       "19208     10921     Babylon 5: The River of Souls         6.374          91   \n",
       "195890   750535          Monochrome: The Chromism         1.000           1   \n",
       "321463   278238                                 Z         0.000           0   \n",
       "160014   651692               Virtual Death Match         6.000           2   \n",
       "18345     10916         Babylon 5: A Call to Arms         6.816          98   \n",
       "10364    240483                   Robot Overlords         4.900         241   \n",
       "401778   760328                     Robopocalypse         0.000           0   \n",
       "61976     74839                      Star Odyssey         2.200          14   \n",
       "239740  1170847            Star Wars: Revelations         0.000           0   \n",
       "174104  1004932                       The Village         9.000           2   \n",
       "8631     456048               The Humanity Bureau         4.823         319   \n",
       "175613   270750                              NOVR         3.500           2   \n",
       "1086      72545  Journey 2: The Mysterious Island         6.145        3942   \n",
       "287112  1245917                      Crimson Star         0.000           0   \n",
       "200931   536422                      Steamwrecked         7.000           1   \n",
       "8        118340           Guardians of the Galaxy         7.906       26638   \n",
       "25858    443297            Moontrap: Target Earth         4.527          56   \n",
       "6364     426285               Fullmetal Alchemist         5.401         507   \n",
       "\n",
       "                          original_title  \\\n",
       "0                              Inception   \n",
       "333127                          Avatar 3   \n",
       "19208      Babylon 5: The River of Souls   \n",
       "195890          Monochrome: The Chromism   \n",
       "321463                                 Z   \n",
       "160014               Virtual Death Match   \n",
       "18345          Babylon 5: A Call to Arms   \n",
       "10364                    Robot Overlords   \n",
       "401778                     Robopocalypse   \n",
       "61976    Sette uomini d'oro nello spazio   \n",
       "239740            Star Wars: Revelations   \n",
       "174104                       The Village   \n",
       "8631                 The Humanity Bureau   \n",
       "175613                              NOVR   \n",
       "1086    Journey 2: The Mysterious Island   \n",
       "287112                      Crimson Star   \n",
       "200931                      Steamwrecked   \n",
       "8                Guardians of the Galaxy   \n",
       "25858             Moontrap: Target Earth   \n",
       "6364                              鋼の錬金術師   \n",
       "\n",
       "                                                 overview  popularity  \\\n",
       "0       [cobb, a, skill, thief, who, commit, corpor, e...      83.952   \n",
       "333127     [the, third, entri, in, the, avatar, franchis]      14.635   \n",
       "19208   [a, group, of, soul, hunter, come, to, babylon...       8.387   \n",
       "195890  [trade, and, sold, like, currenc, the, outcast...       0.600   \n",
       "321463  [the, western, frontier, reemerg, and, as, in,...       2.459   \n",
       "160014  [a, group, of, gamer, are, select, to, take, p...       3.470   \n",
       "18345   [alli, of, the, shadow, seek, reveng, against,...       8.286   \n",
       "10364   [earth, has, been, conquer, by, robot, from, a...      12.406   \n",
       "401778  [in, a, futurist, world, a, human, resist, mov...       0.600   \n",
       "61976   [earth, is, attack, by, an, intergalact, villa...       2.542   \n",
       "239740  [the, last, jedi, fight, to, surviv, when, the...       0.627   \n",
       "174104  [in, a, dystopian, world, where, ai, alreadi, ...       0.600   \n",
       "8631    [in, 2030, the, world, is, in, a, perman, stat...       9.816   \n",
       "175613  [as, their, planet, is, be, rip, apart, two, y...       0.617   \n",
       "1086    [sean, anderson, partner, with, his, mom, s, b...      42.913   \n",
       "287112                                [plot, under, wrap]       0.750   \n",
       "200931  [after, their, lightn, catch, zeppelin, crash,...       0.683   \n",
       "8       [light, year, from, earth, 26, year, after, be...      33.255   \n",
       "25858   [a, long, forgotten, ancient, spacecraft, disc...      10.762   \n",
       "6364    [two, alchemist, brother, go, on, a, quest, fo...      12.863   \n",
       "\n",
       "                                                  tagline  \\\n",
       "0            [your, mind, is, the, scene, of, the, crime]   \n",
       "333127                                                 []   \n",
       "19208                                                  []   \n",
       "195890                                                 []   \n",
       "321463                    [when, vengeanc, becom, justic]   \n",
       "160014                                                 []   \n",
       "18345                                                  []   \n",
       "10364              [mankind, may, fall, hero, will, rise]   \n",
       "401778                                                 []   \n",
       "61976                      [the, earth, s, ultim, disast]   \n",
       "239740                            [the, rebellion, begin]   \n",
       "174104                                                 []   \n",
       "8631    [in, the, near, futur, our, govern, will, deci...   \n",
       "175613                                                 []   \n",
       "1086           [believ, the, imposs, discov, the, incred]   \n",
       "287112                                                 []   \n",
       "200931                                                 []   \n",
       "8                            [all, hero, start, somewher]   \n",
       "25858                                                  []   \n",
       "6364                                                   []   \n",
       "\n",
       "                                              genres  \\\n",
       "0                [action, sciencefiction, adventure]   \n",
       "333127           [action, sciencefiction, adventure]   \n",
       "19208            [action, sciencefiction, adventure]   \n",
       "195890           [action, sciencefiction, adventure]   \n",
       "321463           [adventure, action, sciencefiction]   \n",
       "160014   [horror, action, sciencefiction, adventure]   \n",
       "18345            [action, sciencefiction, adventure]   \n",
       "10364            [sciencefiction, adventure, action]   \n",
       "401778           [sciencefiction, adventure, action]   \n",
       "61976            [sciencefiction, adventure, action]   \n",
       "239740           [sciencefiction, adventure, action]   \n",
       "174104           [sciencefiction, adventure, action]   \n",
       "8631             [action, sciencefiction, adventure]   \n",
       "175613           [action, sciencefiction, adventure]   \n",
       "1086             [adventure, action, sciencefiction]   \n",
       "287112                      [sciencefiction, action]   \n",
       "200931           [action, sciencefiction, adventure]   \n",
       "8                [action, sciencefiction, adventure]   \n",
       "25858            [action, sciencefiction, adventure]   \n",
       "6364    [fantasy, action, sciencefiction, adventure]   \n",
       "\n",
       "                                                 keywords  \\\n",
       "0       [rescu, mission, dream, airplan, pari, franc, ...   \n",
       "333127                                           [sequel]   \n",
       "19208          [alienlifeform, womandirector, spacecentr]   \n",
       "195890                                                 []   \n",
       "321463                                                 []   \n",
       "160014                                                 []   \n",
       "18345   [spacemarin, nightmar, spacewar, alienlifeform...   \n",
       "10364                                      [invas, robot]   \n",
       "401778                                                 []   \n",
       "61976               [alien, robot, spaceopera, outerspac]   \n",
       "239740                                          [fanfilm]   \n",
       "174104                                                 []   \n",
       "8631                                           [dystopia]   \n",
       "175613                                                 []   \n",
       "1086    [mission, giantlizard, missingperson, duringcr...   \n",
       "287112                                                 []   \n",
       "200931  [zeppelin, steampunk, desert, steampow, shortf...   \n",
       "8       [spacecraft, basedoncom, space, orphan, advent...   \n",
       "25858                                                  []   \n",
       "6364                              [basedonmanga, alchemi]   \n",
       "\n",
       "                   directors  \n",
       "0         [christophernolan]  \n",
       "333127        [jamescameron]  \n",
       "19208           [janetgreek]  \n",
       "195890            [kodizene]  \n",
       "321463           [jonscuarn]  \n",
       "160014        [louisawarren]  \n",
       "18345         [michaelvejar]  \n",
       "10364            [jonwright]  \n",
       "401778          [michaelbay]  \n",
       "61976       [alfonsobrescia]  \n",
       "239740          [shanefelux]  \n",
       "174104       [shahriargalib]  \n",
       "8631              [robwking]  \n",
       "175613        [geofforourke]  \n",
       "1086            [bradpeyton]  \n",
       "287112                    []  \n",
       "200931  [christophermatista]  \n",
       "8                [jamesgunn]  \n",
       "25858           [robertdyke]  \n",
       "6364          [fumihikosori]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_full.loc[indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc9ff3-218f-40fd-8f60-1594e4745fc3",
   "metadata": {},
   "source": [
    "#### __Testing the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3affe2f8-31f5-4f97-b5f1-95f20e2be24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>directors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>Inception</td>\n",
       "      <td>[cobb, a, skill, thief, who, commit, corpor, e...</td>\n",
       "      <td>83.952</td>\n",
       "      <td>[your, mind, is, the, scene, of, the, crime]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[rescu, mission, dream, airplan, pari, franc, ...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>43629</td>\n",
       "      <td>Doodlebug</td>\n",
       "      <td>6.500</td>\n",
       "      <td>422</td>\n",
       "      <td>Doodlebug</td>\n",
       "      <td>[in, his, squalid, apart, a, man, tri, to, squ...</td>\n",
       "      <td>5.715</td>\n",
       "      <td>[]</td>\n",
       "      <td>[horror]</td>\n",
       "      <td>[blackandwhit, bug, shoe, shortfilm]</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>577922</td>\n",
       "      <td>Tenet</td>\n",
       "      <td>7.191</td>\n",
       "      <td>8744</td>\n",
       "      <td>Tenet</td>\n",
       "      <td>[arm, with, onli, one, word, tenet, and, fight...</td>\n",
       "      <td>44.025</td>\n",
       "      <td>[time, run, out]</td>\n",
       "      <td>[action, thriller, sciencefiction]</td>\n",
       "      <td>[assassin, espionag, spi, timetravel, mumbaibo...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      title  vote_average  vote_count original_title  \\\n",
       "0      27205  Inception         8.364       34495      Inception   \n",
       "7210   43629  Doodlebug         6.500         422      Doodlebug   \n",
       "354   577922      Tenet         7.191        8744          Tenet   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "0     [cobb, a, skill, thief, who, commit, corpor, e...      83.952   \n",
       "7210  [in, his, squalid, apart, a, man, tri, to, squ...       5.715   \n",
       "354   [arm, with, onli, one, word, tenet, and, fight...      44.025   \n",
       "\n",
       "                                           tagline  \\\n",
       "0     [your, mind, is, the, scene, of, the, crime]   \n",
       "7210                                            []   \n",
       "354                               [time, run, out]   \n",
       "\n",
       "                                   genres  \\\n",
       "0     [action, sciencefiction, adventure]   \n",
       "7210                             [horror]   \n",
       "354    [action, thriller, sciencefiction]   \n",
       "\n",
       "                                               keywords           directors  \n",
       "0     [rescu, mission, dream, airplan, pari, franc, ...  [christophernolan]  \n",
       "7210               [blackandwhit, bug, shoe, shortfilm]  [christophernolan]  \n",
       "354   [assassin, espionag, spi, timetravel, mumbaibo...  [christophernolan]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tmdb_full.loc[[0, 7210, 354]]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcfb667f-36e6-4ddf-8e45-725cde1f2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = []\n",
    "\n",
    "for col,(vect, weight) in vectorizers.items():\n",
    "    col_value = [word_lists_to_str(test[col].to_list(), weight)]\n",
    "    vector = vect.transform(col_value)\n",
    "    test_matrix.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56535bc4-b0af-4b43-a661-4d784ae78d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrices = hstack(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5420f72-5d7c-4e67-9ef7-773ee9e97472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5963281)\n"
     ]
    }
   ],
   "source": [
    "print(test_matrices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12776377-1ad0-4bf4-858e-425a9dc58295",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = modelKNN.kneighbors(test_matrices, n_neighbors=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cddf553-f8aa-4bd1-83d6-b152ba6b2421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>directors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>Inception</td>\n",
       "      <td>[cobb, a, skill, thief, who, commit, corpor, e...</td>\n",
       "      <td>83.952</td>\n",
       "      <td>[your, mind, is, the, scene, of, the, crime]</td>\n",
       "      <td>[action, sciencefiction, adventure]</td>\n",
       "      <td>[rescu, mission, dream, airplan, pari, franc, ...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>577922</td>\n",
       "      <td>Tenet</td>\n",
       "      <td>7.191</td>\n",
       "      <td>8744</td>\n",
       "      <td>Tenet</td>\n",
       "      <td>[arm, with, onli, one, word, tenet, and, fight...</td>\n",
       "      <td>44.025</td>\n",
       "      <td>[time, run, out]</td>\n",
       "      <td>[action, thriller, sciencefiction]</td>\n",
       "      <td>[assassin, espionag, spi, timetravel, mumbaibo...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>43629</td>\n",
       "      <td>Doodlebug</td>\n",
       "      <td>6.500</td>\n",
       "      <td>422</td>\n",
       "      <td>Doodlebug</td>\n",
       "      <td>[in, his, squalid, apart, a, man, tri, to, squ...</td>\n",
       "      <td>5.715</td>\n",
       "      <td>[]</td>\n",
       "      <td>[horror]</td>\n",
       "      <td>[blackandwhit, bug, shoe, shortfilm]</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88982</th>\n",
       "      <td>456684</td>\n",
       "      <td>Larceny</td>\n",
       "      <td>5.700</td>\n",
       "      <td>7</td>\n",
       "      <td>Larceny</td>\n",
       "      <td>[a, man, break, into, a, flat, startl, the, oc...</td>\n",
       "      <td>1.452</td>\n",
       "      <td>[]</td>\n",
       "      <td>[drama, thriller, comedy]</td>\n",
       "      <td>[burglari, lostfilm, neonoir, breakingandent, ...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>11660</td>\n",
       "      <td>Following</td>\n",
       "      <td>7.151</td>\n",
       "      <td>1412</td>\n",
       "      <td>Following</td>\n",
       "      <td>[bill, an, idl, unemploy, aspir, writer, walk,...</td>\n",
       "      <td>12.093</td>\n",
       "      <td>[you, re, never, alon]</td>\n",
       "      <td>[drama, thriller]</td>\n",
       "      <td>[london, england, robberi, stalker, thief, sta...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287112</th>\n",
       "      <td>1245917</td>\n",
       "      <td>Crimson Star</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Crimson Star</td>\n",
       "      <td>[plot, under, wrap]</td>\n",
       "      <td>0.750</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sciencefiction, action]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157336</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>32571</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>[the, adventur, of, a, group, of, explor, who,...</td>\n",
       "      <td>140.241</td>\n",
       "      <td>[mankind, was, born, on, earth, it, was, never...</td>\n",
       "      <td>[adventure, drama, sciencefiction]</td>\n",
       "      <td>[rescu, futur, spacecraft, raceagainsttim, art...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160014</th>\n",
       "      <td>651692</td>\n",
       "      <td>Virtual Death Match</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2</td>\n",
       "      <td>Virtual Death Match</td>\n",
       "      <td>[a, group, of, gamer, are, select, to, take, p...</td>\n",
       "      <td>3.470</td>\n",
       "      <td>[]</td>\n",
       "      <td>[horror, action, sciencefiction, adventure]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[louisawarren]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1124</td>\n",
       "      <td>The Prestige</td>\n",
       "      <td>8.203</td>\n",
       "      <td>14696</td>\n",
       "      <td>The Prestige</td>\n",
       "      <td>[a, mysteri, stori, of, two, magician, whose, ...</td>\n",
       "      <td>48.832</td>\n",
       "      <td>[are, you, watch, close]</td>\n",
       "      <td>[drama, mystery, sciencefiction]</td>\n",
       "      <td>[dyinganddeath, suicid, classsocieti, magic, c...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>272</td>\n",
       "      <td>Batman Begins</td>\n",
       "      <td>7.701</td>\n",
       "      <td>19561</td>\n",
       "      <td>Batman Begins</td>\n",
       "      <td>[driven, by, tragedi, billionair, bruce, wayn,...</td>\n",
       "      <td>66.286</td>\n",
       "      <td>[evil, fear, the, knight]</td>\n",
       "      <td>[action, crime, drama]</td>\n",
       "      <td>[martialart, undercov, lossoflovedon, secretid...</td>\n",
       "      <td>[christophernolan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                title  vote_average  vote_count  \\\n",
       "0         27205            Inception         8.364       34495   \n",
       "354      577922                Tenet         7.191        8744   \n",
       "7210      43629            Doodlebug         6.500         422   \n",
       "88982    456684              Larceny         5.700           7   \n",
       "2959      11660            Following         7.151        1412   \n",
       "287112  1245917         Crimson Star         0.000           0   \n",
       "1        157336         Interstellar         8.417       32571   \n",
       "160014   651692  Virtual Death Match         6.000           2   \n",
       "114        1124         The Prestige         8.203       14696   \n",
       "41          272        Batman Begins         7.701       19561   \n",
       "\n",
       "             original_title  \\\n",
       "0                 Inception   \n",
       "354                   Tenet   \n",
       "7210              Doodlebug   \n",
       "88982               Larceny   \n",
       "2959              Following   \n",
       "287112         Crimson Star   \n",
       "1              Interstellar   \n",
       "160014  Virtual Death Match   \n",
       "114            The Prestige   \n",
       "41            Batman Begins   \n",
       "\n",
       "                                                 overview  popularity  \\\n",
       "0       [cobb, a, skill, thief, who, commit, corpor, e...      83.952   \n",
       "354     [arm, with, onli, one, word, tenet, and, fight...      44.025   \n",
       "7210    [in, his, squalid, apart, a, man, tri, to, squ...       5.715   \n",
       "88982   [a, man, break, into, a, flat, startl, the, oc...       1.452   \n",
       "2959    [bill, an, idl, unemploy, aspir, writer, walk,...      12.093   \n",
       "287112                                [plot, under, wrap]       0.750   \n",
       "1       [the, adventur, of, a, group, of, explor, who,...     140.241   \n",
       "160014  [a, group, of, gamer, are, select, to, take, p...       3.470   \n",
       "114     [a, mysteri, stori, of, two, magician, whose, ...      48.832   \n",
       "41      [driven, by, tragedi, billionair, bruce, wayn,...      66.286   \n",
       "\n",
       "                                                  tagline  \\\n",
       "0            [your, mind, is, the, scene, of, the, crime]   \n",
       "354                                      [time, run, out]   \n",
       "7210                                                   []   \n",
       "88982                                                  []   \n",
       "2959                               [you, re, never, alon]   \n",
       "287112                                                 []   \n",
       "1       [mankind, was, born, on, earth, it, was, never...   \n",
       "160014                                                 []   \n",
       "114                              [are, you, watch, close]   \n",
       "41                              [evil, fear, the, knight]   \n",
       "\n",
       "                                             genres  \\\n",
       "0               [action, sciencefiction, adventure]   \n",
       "354              [action, thriller, sciencefiction]   \n",
       "7210                                       [horror]   \n",
       "88982                     [drama, thriller, comedy]   \n",
       "2959                              [drama, thriller]   \n",
       "287112                     [sciencefiction, action]   \n",
       "1                [adventure, drama, sciencefiction]   \n",
       "160014  [horror, action, sciencefiction, adventure]   \n",
       "114                [drama, mystery, sciencefiction]   \n",
       "41                           [action, crime, drama]   \n",
       "\n",
       "                                                 keywords           directors  \n",
       "0       [rescu, mission, dream, airplan, pari, franc, ...  [christophernolan]  \n",
       "354     [assassin, espionag, spi, timetravel, mumbaibo...  [christophernolan]  \n",
       "7210                 [blackandwhit, bug, shoe, shortfilm]  [christophernolan]  \n",
       "88982   [burglari, lostfilm, neonoir, breakingandent, ...  [christophernolan]  \n",
       "2959    [london, england, robberi, stalker, thief, sta...  [christophernolan]  \n",
       "287112                                                 []                  []  \n",
       "1       [rescu, futur, spacecraft, raceagainsttim, art...  [christophernolan]  \n",
       "160014                                                 []      [louisawarren]  \n",
       "114     [dyinganddeath, suicid, classsocieti, magic, c...  [christophernolan]  \n",
       "41      [martialart, undercov, lossoflovedon, secretid...  [christophernolan]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_full.loc[indices[0]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad698532-6f3c-4fe1-a65d-499ff22affc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __Saving the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b624c7f-2377-4884-a6f7-9b8a0d421889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/movies_recommendation_engine_model.sav']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_model = '../model/movies_recommendation_engine_model.sav'\n",
    "joblib.dump(modelKNN, filename_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d53f05c0-2e89-488b-9abd-a29a8751162c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/movies_recommendation_engine_vectorizers.sav']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_vectorizers= '../model/movies_recommendation_engine_vectorizers.sav'\n",
    "joblib.dump(vectorizers, filename_vectorizers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e62aa8-204d-46fe-8aa1-c5e2e9cd4639",
   "metadata": {},
   "source": [
    "# __API: API OF SYSTEM RECOMMENDATION ENGINE__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f78bc0a-d523-45f7-848a-8dc7c55c0dd3",
   "metadata": {},
   "source": [
    "## __THE ML MODEL__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb54ac2-fa40-4dde-a3f7-d3a64868f1b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __Python Imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3421f323-7dd0-45ca-97e6-f12af6a5da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import hstack\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2147d01c-5eea-49bd-aa52-f4f1e5b07293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gabriel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "tokenizer = RegexpTokenizer(r'\\w+').tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6efe8e1-ecf2-4131-9095-0970db548cc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __UTILS FUNCTIONS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aca1783-18ad-435c-a93e-dbd353e68e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text: str, lower=True, clean=True) -> str:\n",
    "    text = text.strip()\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    if clean:\n",
    "        text = re.sub(r'[^a-z\\s]',\" \", text) if lower else re.sub(r'[^a-zA-Z\\s]',\" \", text)\n",
    "    return text\n",
    "\n",
    "def split_and_clean_str(x: str, delimiter=\",\", remove_spaces: bool=False, to_lower: bool=True, clean=True):\n",
    "    new_list = []\n",
    "    if isinstance(x, str) and x != None and len(x.strip()) > 0 and x !='\\\\N' and x != np.nan:\n",
    "        new_list = [clean_str(val, to_lower, clean) for val in x.split(delimiter) if val.strip() != \"\"]\n",
    "    if isinstance(x, list):\n",
    "        new_list = [clean_str(val, to_lower, clean) for val in x if val and val.strip() != \"\"]\n",
    "    if remove_spaces:\n",
    "        new_list = [val.replace(\" \", \"\") for val in new_list]\n",
    "    return new_list\n",
    "\n",
    "def word_lists_to_str(word_lists: list, weight) -> str:\n",
    "    return \" \".join([word for word_list in word_lists  \n",
    "              for word in word_list*weight if word not in stopwords.words('english')])\n",
    "\n",
    "\n",
    "def split_with_tokenizer(text: str) -> list:\n",
    "    if isinstance(text, str):\n",
    "        return tokenizer(text)\n",
    "    return []\n",
    "\n",
    "def nplist_to_native_python(nplist: np.array):\n",
    "    return [x.item() for x in nplist]\n",
    "\n",
    "def clean_dataframe(dataframe: pd.DataFrame):\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe.fillna({'tagline':'', 'overview': '', 'title': '', 'original_title': '', 'poster_path': '', 'release_date':'', 'vote_average': 0}, inplace=True)\n",
    "    dataframe['directors'] = dataframe['directors'].apply(lambda x: split_and_clean_str(x, to_lower=False, clean=False))\n",
    "    dataframe['genres'] = dataframe['genres'].apply(lambda x: split_and_clean_str(x, to_lower=False))    \n",
    "    dataframe['keywords'] = dataframe['keywords'].apply(split_and_clean_str)\n",
    "    return dataframe\n",
    "\n",
    "def process_dataframe(dataframe: pd.DataFrame):\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe['directors'] = dataframe['directors'].apply(lambda x: split_and_clean_str(x, remove_spaces=True))\n",
    "    dataframe['genres'] = dataframe['genres'].apply(lambda x: split_and_clean_str(x, remove_spaces=True))    \n",
    "    dataframe['keywords'] = dataframe['keywords'].apply(split_and_clean_str)    \n",
    "    dataframe['overview'] = dataframe['overview'].apply(split_with_tokenizer)    \n",
    "    dataframe['tagline'] = dataframe['tagline'].apply(split_with_tokenizer)    \n",
    "    dataframe['keywords'] = dataframe['keywords'].apply(lambda x: [stemmer.stem(i).replace(\" \", \"\") for i in x])    \n",
    "    dataframe['tagline'] = dataframe['tagline'].apply(lambda x: [stemmer.stem(i) for i in x])    \n",
    "    dataframe['overview'] = dataframe['overview'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c12098-70df-4ed5-b113-4dc7c4de830b",
   "metadata": {},
   "source": [
    "### __IMPORT THE ML MODEL AND OTHERS__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89228f8-d9e2-4495-ad47-d5a5803ed5dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### __Import the dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798f7f3f-ffc3-4ee2-af40-45f40ec7fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full = pd.read_csv(filepath_or_buffer=\"../Data_Files/data/TMDB_movies_full.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0b9418-67d4-4751-acac-b23dbf0649b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_full = clean_dataframe(tmdb_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee20e9-cb31-41c1-9bba-c8779a2dc1c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### __Import the Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ac88cb-ac8b-4f2c-85ca-cad5e2b30fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_model = '../model/movies_recommendation_engine_model.sav'\n",
    "model = joblib.load(filename_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae27af3-d0ab-47f8-9a7b-27ef78f7eade",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### __Import the Vectorizers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b40896c9-ab3f-4cb0-b97e-18e67e6a3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_vectorizer = '../model/movies_recommendation_engine_vectorizers.sav'\n",
    "vectorizers = joblib.load(filename_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1909ad-d867-4a0b-917c-c2a1dac5585e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### __GETTING THE RECOMENDATIONS__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbe364-5ee5-4dc9-a7bb-546f36a06417",
   "metadata": {},
   "source": [
    "#### __The recommendation function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13ba9ab0-52de-4b60-b80f-a55fcfe2e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_engine(dataframe: pd.DataFrame) -> list[int]:\n",
    "    ids = dataframe['id'].to_list()\n",
    "    dataframe = process_dataframe(dataframe)\n",
    "    matrix = []\n",
    "    \n",
    "    for col,(vect, weight) in vectorizers.items():\n",
    "        col_value = [word_lists_to_str(dataframe[col].to_list(), weight)]\n",
    "        vector = vect.transform(col_value)\n",
    "        matrix.append(vector)\n",
    "        \n",
    "    matrices = hstack(matrix)\n",
    "    distances, indices = model.kneighbors(matrices, n_neighbors=100)\n",
    "    \n",
    "    return clean_dataframe(tmdb_full.loc[indices[0]].loc[~tmdb_full['id'].isin(ids)].sort_values('popularity', ascending=False).head(10)).to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48ad2a-be75-4fae-bd0f-d4309157fc63",
   "metadata": {},
   "source": [
    "## THE SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57682126-3bf5-45a1-ae6c-2cda878a96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad78a0-9d7a-47d2-bd9d-d754f5a02cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "origins = [\n",
    "    \"http://localhost\",\n",
    "    \"http://localhost:5173\",\n",
    "]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    id: int = None\n",
    "    title: str = ''\n",
    "    genres: list[str] = []\n",
    "    directors: list[str] = []\n",
    "    overview: str = ''\n",
    "    tagline: str = ''\n",
    "    keywords: list[str] = []\n",
    "    release_date: str = ''\n",
    "    poster_path: str = ''\n",
    "    vote_average: float = None\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"Message\": \"This is a recommendation system engine\"}\n",
    "\n",
    "@app.post(\"/recommendations\", response_model=list[Movie])\n",
    "def get_recommendations(movies: list[Movie]):\n",
    "    df = pd.DataFrame([movie.dict() for movie in movies])\n",
    "    movies_dict = get_recommendations_engine(df)\n",
    "    return movies_dict\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    uvicorn.run(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
